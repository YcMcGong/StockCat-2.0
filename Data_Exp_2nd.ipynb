{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/yicong/anaconda3/envs/Standard_ML_Dev/lib/python3.5/site-packages/fix_yahoo_finance/__init__.py:43: DeprecationWarning: \n",
      "    Auto-overriding of pandas_datareader's get_data_yahoo() is deprecated and no longer available.\n",
      "    Use pdr_override() to explicitly override it.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from pandas_datareader import data as pdr\n",
    "import fix_yahoo_finance as yf\n",
    "yf.pdr_override()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 downloaded"
     ]
    }
   ],
   "source": [
    "start_date = \"2013-01-01\"\n",
    "end_date = \"2017-11-02\"\n",
    "\n",
    "data_AAPL = pdr.get_data_yahoo(\"FB\", start=start_date, end=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  28.           27.77000046   28.76000023 ...,  180.05999756  182.66000366\n",
      "  178.91999817]\n"
     ]
    }
   ],
   "source": [
    "data_AAPL_close = (data_AAPL['Close'].values.astype('float32'))\n",
    "print(data_AAPL_close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00821427  0.03564997  0.02294853 ...,  0.00105633  0.01443967\n",
      " -0.02047523]\n",
      "560\n",
      "659\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yicong/anaconda3/envs/Standard_ML_Dev/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/yicong/anaconda3/envs/Standard_ML_Dev/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "tar = np.divide(np.diff(data_AAPL_close), data_AAPL_close[:-1])\n",
    "target = []\n",
    "for i in tar:\n",
    "#     if i>=0.02:\n",
    "#         target.append(6)\n",
    "#     elif i>=0.008 and i<0.02:\n",
    "#         target.append(5)\n",
    "#     elif i>=0.001 and i<0.008:\n",
    "#         target.append(4)\n",
    "#     elif i<= -0.02 :\n",
    "#         target.append(0)\n",
    "#     elif i>-0.02 and i<=-0.008:\n",
    "#         target.append(1)\n",
    "#     elif i>-0.008 and i<-0.001:\n",
    "#         target.append(2)\n",
    "    if i >0:\n",
    "        target.append(1)\n",
    "    else:\n",
    "        target.append(0)\n",
    "        \n",
    "print(tar)\n",
    "\n",
    "# Show target distribution\n",
    "for i in range(7):\n",
    "    print(target.count(i))\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# enc = OneHotEncoder(sparse=False)\n",
    "# target=np.array(target).reshape(-1,1)\n",
    "# enc.fit(target)\n",
    "# target = enc.transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  28.        ]\n",
      " [  27.77000046]\n",
      " [  28.76000023]\n",
      " ..., \n",
      " [ 179.86999512]\n",
      " [ 180.05999756]\n",
      " [ 182.66000366]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1219, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_stock = 1\n",
    "length = len(data_AAPL_close)-1\n",
    "prices = np.reshape(data_AAPL_close[:-1], (length,number_of_stock))\n",
    "print(prices)\n",
    "prices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcb21e72a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03192288]\n",
      " [ 0.03048322]\n",
      " [ 0.03668001]\n",
      " ..., \n",
      " [ 0.9825362 ]\n",
      " [ 0.98372555]\n",
      " [ 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "prices = scaler.fit_transform(prices)\n",
    "\n",
    "plt.plot(prices)\n",
    "plt.show()\n",
    "print(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975 244\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(prices) * 0.80)\n",
    "test_size = len(prices) - train_size\n",
    "train, test = prices[0:train_size,:], prices[train_size:len(prices),:]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # convert an array of values into a dataset matrix\n",
    "# def create_dataset(dataset, look_back=1):\n",
    "# \tdataX, dataY = [], []\n",
    "# \tfor i in range(len(dataset)-look_back-1):\n",
    "# \t\ta = dataset[i:(i+look_back), :]\n",
    "# \t\tdataX.append(a)\n",
    "# \t\tdataY.append(dataset[i + look_back, :])\n",
    "# \treturn np.array(dataX), np.array(dataY)\n",
    "\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(target[i + look_back])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(959,)\n",
      "(959, 15, 1)\n"
     ]
    }
   ],
   "source": [
    "# reshape into X=t and Y=t+1\n",
    "look_back = 15\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], look_back, train.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], look_back, test.shape[1]))\n",
    "\n",
    "print(trainY.shape)\n",
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, activation = 'sigmoid', input_shape=(look_back, number_of_stock)))\n",
    "# model.add(LSTM(100))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(LSTM(100, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#Step 2 Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 863 samples, validate on 96 samples\n",
      "Epoch 1/1500\n",
      "Epoch 00000: val_loss improved from inf to 0.68492, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 2/1500\n",
      "Epoch 00001: val_loss improved from 0.68492 to 0.68492, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 3/1500\n",
      "Epoch 00002: val_loss improved from 0.68492 to 0.68491, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 4/1500\n",
      "Epoch 00003: val_loss improved from 0.68491 to 0.68491, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 5/1500\n",
      "Epoch 00004: val_loss improved from 0.68491 to 0.68490, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yicong/anaconda3/envs/Standard_ML_Dev/lib/python3.5/site-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/1500\n",
      "Epoch 00005: val_loss improved from 0.68490 to 0.68489, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 7/1500\n",
      "Epoch 00006: val_loss improved from 0.68489 to 0.68489, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 8/1500\n",
      "Epoch 00007: val_loss improved from 0.68489 to 0.68488, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 9/1500\n",
      "Epoch 00008: val_loss improved from 0.68488 to 0.68488, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 10/1500\n",
      "Epoch 00009: val_loss improved from 0.68488 to 0.68487, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 11/1500\n",
      "Epoch 00010: val_loss improved from 0.68487 to 0.68486, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 12/1500\n",
      "Epoch 00011: val_loss improved from 0.68486 to 0.68486, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 13/1500\n",
      "Epoch 00012: val_loss improved from 0.68486 to 0.68486, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 14/1500\n",
      "Epoch 00013: val_loss improved from 0.68486 to 0.68485, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 15/1500\n",
      "Epoch 00014: val_loss improved from 0.68485 to 0.68485, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 16/1500\n",
      "Epoch 00015: val_loss improved from 0.68485 to 0.68485, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 17/1500\n",
      "Epoch 00016: val_loss improved from 0.68485 to 0.68484, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 18/1500\n",
      "Epoch 00017: val_loss improved from 0.68484 to 0.68484, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 19/1500\n",
      "Epoch 00018: val_loss improved from 0.68484 to 0.68484, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 20/1500\n",
      "Epoch 00019: val_loss improved from 0.68484 to 0.68484, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 21/1500\n",
      "Epoch 00020: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 22/1500\n",
      "Epoch 00021: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 23/1500\n",
      "Epoch 00022: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 24/1500\n",
      "Epoch 00023: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 25/1500\n",
      "Epoch 00024: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 26/1500\n",
      "Epoch 00025: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 27/1500\n",
      "Epoch 00026: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 28/1500\n",
      "Epoch 00027: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 29/1500\n",
      "Epoch 00028: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 30/1500\n",
      "Epoch 00029: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 31/1500\n",
      "Epoch 00030: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 32/1500\n",
      "Epoch 00031: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 33/1500\n",
      "Epoch 00032: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 34/1500\n",
      "Epoch 00033: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 35/1500\n",
      "Epoch 00034: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 36/1500\n",
      "Epoch 00035: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 37/1500\n",
      "Epoch 00036: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 38/1500\n",
      "Epoch 00037: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 39/1500\n",
      "Epoch 00038: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 40/1500\n",
      "Epoch 00039: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 41/1500\n",
      "Epoch 00040: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 42/1500\n",
      "Epoch 00041: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 43/1500\n",
      "Epoch 00042: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 44/1500\n",
      "Epoch 00043: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 45/1500\n",
      "Epoch 00044: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 46/1500\n",
      "Epoch 00045: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 47/1500\n",
      "Epoch 00046: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 48/1500\n",
      "Epoch 00047: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 49/1500\n",
      "Epoch 00048: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 50/1500\n",
      "Epoch 00049: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 51/1500\n",
      "Epoch 00050: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 52/1500\n",
      "Epoch 00051: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 53/1500\n",
      "Epoch 00052: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 54/1500\n",
      "Epoch 00053: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 55/1500\n",
      "Epoch 00054: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 56/1500\n",
      "Epoch 00055: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 57/1500\n",
      "Epoch 00056: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 58/1500\n",
      "Epoch 00057: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 59/1500\n",
      "Epoch 00058: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 60/1500\n",
      "Epoch 00059: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 61/1500\n",
      "Epoch 00060: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 62/1500\n",
      "Epoch 00061: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 63/1500\n",
      "Epoch 00062: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 64/1500\n",
      "Epoch 00063: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 65/1500\n",
      "Epoch 00064: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 66/1500\n",
      "Epoch 00065: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 67/1500\n",
      "Epoch 00066: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 68/1500\n",
      "Epoch 00067: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 69/1500\n",
      "Epoch 00068: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 70/1500\n",
      "Epoch 00069: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 71/1500\n",
      "Epoch 00070: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 72/1500\n",
      "Epoch 00071: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 73/1500\n",
      "Epoch 00072: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 74/1500\n",
      "Epoch 00073: val_loss improved from 0.68484 to 0.68484, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 75/1500\n",
      "Epoch 00074: val_loss improved from 0.68484 to 0.68484, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 76/1500\n",
      "Epoch 00075: val_loss improved from 0.68484 to 0.68484, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 77/1500\n",
      "Epoch 00076: val_loss improved from 0.68484 to 0.68484, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 78/1500\n",
      "Epoch 00077: val_loss improved from 0.68484 to 0.68484, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 79/1500\n",
      "Epoch 00078: val_loss improved from 0.68484 to 0.68484, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 80/1500\n",
      "Epoch 00079: val_loss improved from 0.68484 to 0.68484, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 81/1500\n",
      "Epoch 00080: val_loss improved from 0.68484 to 0.68484, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 82/1500\n",
      "Epoch 00081: val_loss improved from 0.68484 to 0.68484, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 83/1500\n",
      "Epoch 00082: val_loss improved from 0.68484 to 0.68484, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 84/1500\n",
      "Epoch 00083: val_loss improved from 0.68484 to 0.68484, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 85/1500\n",
      "Epoch 00084: val_loss improved from 0.68484 to 0.68484, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 86/1500\n",
      "Epoch 00085: val_loss improved from 0.68484 to 0.68484, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 87/1500\n",
      "Epoch 00086: val_loss improved from 0.68484 to 0.68484, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 88/1500\n",
      "Epoch 00087: val_loss improved from 0.68484 to 0.68484, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 89/1500\n",
      "Epoch 00088: val_loss improved from 0.68484 to 0.68484, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 90/1500\n",
      "Epoch 00089: val_loss improved from 0.68484 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 91/1500\n",
      "Epoch 00090: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 92/1500\n",
      "Epoch 00091: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 93/1500\n",
      "Epoch 00092: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 94/1500\n",
      "Epoch 00093: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 95/1500\n",
      "Epoch 00094: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 96/1500\n",
      "Epoch 00095: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 97/1500\n",
      "Epoch 00096: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 98/1500\n",
      "Epoch 00097: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 99/1500\n",
      "Epoch 00098: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 100/1500\n",
      "Epoch 00099: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 101/1500\n",
      "Epoch 00100: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 102/1500\n",
      "Epoch 00101: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 103/1500\n",
      "Epoch 00102: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 104/1500\n",
      "Epoch 00103: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 105/1500\n",
      "Epoch 00104: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 106/1500\n",
      "Epoch 00105: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 107/1500\n",
      "Epoch 00106: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 108/1500\n",
      "Epoch 00107: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 109/1500\n",
      "Epoch 00108: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 110/1500\n",
      "Epoch 00109: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 111/1500\n",
      "Epoch 00110: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 112/1500\n",
      "Epoch 00111: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 113/1500\n",
      "Epoch 00112: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 114/1500\n",
      "Epoch 00113: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 115/1500\n",
      "Epoch 00114: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 116/1500\n",
      "Epoch 00115: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 117/1500\n",
      "Epoch 00116: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 118/1500\n",
      "Epoch 00117: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 119/1500\n",
      "Epoch 00118: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 120/1500\n",
      "Epoch 00119: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 121/1500\n",
      "Epoch 00120: val_loss improved from 0.68483 to 0.68483, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 122/1500\n",
      "Epoch 00121: val_loss improved from 0.68483 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 123/1500\n",
      "Epoch 00122: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 124/1500\n",
      "Epoch 00123: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 125/1500\n",
      "Epoch 00124: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 126/1500\n",
      "Epoch 00125: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 127/1500\n",
      "Epoch 00126: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 128/1500\n",
      "Epoch 00127: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 129/1500\n",
      "Epoch 00128: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 130/1500\n",
      "Epoch 00129: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 131/1500\n",
      "Epoch 00130: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 132/1500\n",
      "Epoch 00131: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 133/1500\n",
      "Epoch 00132: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 134/1500\n",
      "Epoch 00133: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 135/1500\n",
      "Epoch 00134: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 136/1500\n",
      "Epoch 00135: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 137/1500\n",
      "Epoch 00136: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 138/1500\n",
      "Epoch 00137: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 139/1500\n",
      "Epoch 00138: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 140/1500\n",
      "Epoch 00139: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 141/1500\n",
      "Epoch 00140: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 142/1500\n",
      "Epoch 00141: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 143/1500\n",
      "Epoch 00142: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 144/1500\n",
      "Epoch 00143: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 145/1500\n",
      "Epoch 00144: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 146/1500\n",
      "Epoch 00145: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 147/1500\n",
      "Epoch 00146: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 148/1500\n",
      "Epoch 00147: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 149/1500\n",
      "Epoch 00148: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 150/1500\n",
      "Epoch 00149: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 151/1500\n",
      "Epoch 00150: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 152/1500\n",
      "Epoch 00151: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 153/1500\n",
      "Epoch 00152: val_loss improved from 0.68482 to 0.68482, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 154/1500\n",
      "Epoch 00153: val_loss improved from 0.68482 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 155/1500\n",
      "Epoch 00154: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 156/1500\n",
      "Epoch 00155: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 157/1500\n",
      "Epoch 00156: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 158/1500\n",
      "Epoch 00157: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 159/1500\n",
      "Epoch 00158: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 160/1500\n",
      "Epoch 00159: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 161/1500\n",
      "Epoch 00160: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 162/1500\n",
      "Epoch 00161: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 163/1500\n",
      "Epoch 00162: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 164/1500\n",
      "Epoch 00163: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 165/1500\n",
      "Epoch 00164: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 166/1500\n",
      "Epoch 00165: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 167/1500\n",
      "Epoch 00166: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 168/1500\n",
      "Epoch 00167: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 169/1500\n",
      "Epoch 00168: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 170/1500\n",
      "Epoch 00169: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 171/1500\n",
      "Epoch 00170: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 172/1500\n",
      "Epoch 00171: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 173/1500\n",
      "Epoch 00172: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 174/1500\n",
      "Epoch 00173: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 175/1500\n",
      "Epoch 00174: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 176/1500\n",
      "Epoch 00175: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 177/1500\n",
      "Epoch 00176: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 178/1500\n",
      "Epoch 00177: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 179/1500\n",
      "Epoch 00178: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 180/1500\n",
      "Epoch 00179: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 181/1500\n",
      "Epoch 00180: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 182/1500\n",
      "Epoch 00181: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 183/1500\n",
      "Epoch 00182: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 184/1500\n",
      "Epoch 00183: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 185/1500\n",
      "Epoch 00184: val_loss improved from 0.68481 to 0.68481, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 186/1500\n",
      "Epoch 00185: val_loss improved from 0.68481 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 187/1500\n",
      "Epoch 00186: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 188/1500\n",
      "Epoch 00187: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 189/1500\n",
      "Epoch 00188: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 190/1500\n",
      "Epoch 00189: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 191/1500\n",
      "Epoch 00190: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 192/1500\n",
      "Epoch 00191: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 193/1500\n",
      "Epoch 00192: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 194/1500\n",
      "Epoch 00193: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 195/1500\n",
      "Epoch 00194: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 196/1500\n",
      "Epoch 00195: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 197/1500\n",
      "Epoch 00196: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 198/1500\n",
      "Epoch 00197: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 199/1500\n",
      "Epoch 00198: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 200/1500\n",
      "Epoch 00199: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 201/1500\n",
      "Epoch 00200: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 202/1500\n",
      "Epoch 00201: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 203/1500\n",
      "Epoch 00202: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 204/1500\n",
      "Epoch 00203: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 205/1500\n",
      "Epoch 00204: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 206/1500\n",
      "Epoch 00205: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 207/1500\n",
      "Epoch 00206: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 208/1500\n",
      "Epoch 00207: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 209/1500\n",
      "Epoch 00208: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 210/1500\n",
      "Epoch 00209: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 211/1500\n",
      "Epoch 00210: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 212/1500\n",
      "Epoch 00211: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 213/1500\n",
      "Epoch 00212: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 214/1500\n",
      "Epoch 00213: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 215/1500\n",
      "Epoch 00214: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 216/1500\n",
      "Epoch 00215: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 217/1500\n",
      "Epoch 00216: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 218/1500\n",
      "Epoch 00217: val_loss improved from 0.68480 to 0.68480, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 219/1500\n",
      "Epoch 00218: val_loss improved from 0.68480 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 220/1500\n",
      "Epoch 00219: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 221/1500\n",
      "Epoch 00220: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 222/1500\n",
      "Epoch 00221: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 223/1500\n",
      "Epoch 00222: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 224/1500\n",
      "Epoch 00223: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 225/1500\n",
      "Epoch 00224: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 226/1500\n",
      "Epoch 00225: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 227/1500\n",
      "Epoch 00226: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 228/1500\n",
      "Epoch 00227: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 229/1500\n",
      "Epoch 00228: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 230/1500\n",
      "Epoch 00229: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 231/1500\n",
      "Epoch 00230: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 232/1500\n",
      "Epoch 00231: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 233/1500\n",
      "Epoch 00232: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 234/1500\n",
      "Epoch 00233: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 235/1500\n",
      "Epoch 00234: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 236/1500\n",
      "Epoch 00235: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 237/1500\n",
      "Epoch 00236: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 238/1500\n",
      "Epoch 00237: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 239/1500\n",
      "Epoch 00238: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 240/1500\n",
      "Epoch 00239: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 241/1500\n",
      "Epoch 00240: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 242/1500\n",
      "Epoch 00241: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 243/1500\n",
      "Epoch 00242: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 244/1500\n",
      "Epoch 00243: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 245/1500\n",
      "Epoch 00244: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 246/1500\n",
      "Epoch 00245: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 247/1500\n",
      "Epoch 00246: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 248/1500\n",
      "Epoch 00247: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 249/1500\n",
      "Epoch 00248: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 250/1500\n",
      "Epoch 00249: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 251/1500\n",
      "Epoch 00250: val_loss improved from 0.68479 to 0.68479, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 252/1500\n",
      "Epoch 00251: val_loss improved from 0.68479 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 253/1500\n",
      "Epoch 00252: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 254/1500\n",
      "Epoch 00253: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 255/1500\n",
      "Epoch 00254: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 256/1500\n",
      "Epoch 00255: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 257/1500\n",
      "Epoch 00256: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 258/1500\n",
      "Epoch 00257: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 259/1500\n",
      "Epoch 00258: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 260/1500\n",
      "Epoch 00259: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 261/1500\n",
      "Epoch 00260: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 262/1500\n",
      "Epoch 00261: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 263/1500\n",
      "Epoch 00262: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 264/1500\n",
      "Epoch 00263: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 265/1500\n",
      "Epoch 00264: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 266/1500\n",
      "Epoch 00265: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 267/1500\n",
      "Epoch 00266: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 268/1500\n",
      "Epoch 00267: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 269/1500\n",
      "Epoch 00268: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 270/1500\n",
      "Epoch 00269: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 271/1500\n",
      "Epoch 00270: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 272/1500\n",
      "Epoch 00271: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 273/1500\n",
      "Epoch 00272: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 274/1500\n",
      "Epoch 00273: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 275/1500\n",
      "Epoch 00274: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 276/1500\n",
      "Epoch 00275: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 277/1500\n",
      "Epoch 00276: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 278/1500\n",
      "Epoch 00277: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 279/1500\n",
      "Epoch 00278: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 280/1500\n",
      "Epoch 00279: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 281/1500\n",
      "Epoch 00280: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 282/1500\n",
      "Epoch 00281: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 283/1500\n",
      "Epoch 00282: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 284/1500\n",
      "Epoch 00283: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 285/1500\n",
      "Epoch 00284: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 286/1500\n",
      "Epoch 00285: val_loss improved from 0.68478 to 0.68478, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 287/1500\n",
      "Epoch 00286: val_loss improved from 0.68478 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 288/1500\n",
      "Epoch 00287: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 289/1500\n",
      "Epoch 00288: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 290/1500\n",
      "Epoch 00289: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 291/1500\n",
      "Epoch 00290: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 292/1500\n",
      "Epoch 00291: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 293/1500\n",
      "Epoch 00292: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 294/1500\n",
      "Epoch 00293: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 295/1500\n",
      "Epoch 00294: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 296/1500\n",
      "Epoch 00295: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 297/1500\n",
      "Epoch 00296: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 298/1500\n",
      "Epoch 00297: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 299/1500\n",
      "Epoch 00298: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 300/1500\n",
      "Epoch 00299: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 301/1500\n",
      "Epoch 00300: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 302/1500\n",
      "Epoch 00301: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 303/1500\n",
      "Epoch 00302: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 304/1500\n",
      "Epoch 00303: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 305/1500\n",
      "Epoch 00304: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 306/1500\n",
      "Epoch 00305: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 307/1500\n",
      "Epoch 00306: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 308/1500\n",
      "Epoch 00307: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 309/1500\n",
      "Epoch 00308: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 310/1500\n",
      "Epoch 00309: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 311/1500\n",
      "Epoch 00310: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 312/1500\n",
      "Epoch 00311: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 313/1500\n",
      "Epoch 00312: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 314/1500\n",
      "Epoch 00313: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 315/1500\n",
      "Epoch 00314: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 316/1500\n",
      "Epoch 00315: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 317/1500\n",
      "Epoch 00316: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 318/1500\n",
      "Epoch 00317: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 319/1500\n",
      "Epoch 00318: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 320/1500\n",
      "Epoch 00319: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 321/1500\n",
      "Epoch 00320: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 322/1500\n",
      "Epoch 00321: val_loss improved from 0.68477 to 0.68477, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 323/1500\n",
      "Epoch 00322: val_loss improved from 0.68477 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 324/1500\n",
      "Epoch 00323: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 325/1500\n",
      "Epoch 00324: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 326/1500\n",
      "Epoch 00325: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 327/1500\n",
      "Epoch 00326: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 328/1500\n",
      "Epoch 00327: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 329/1500\n",
      "Epoch 00328: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 330/1500\n",
      "Epoch 00329: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 331/1500\n",
      "Epoch 00330: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 332/1500\n",
      "Epoch 00331: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 333/1500\n",
      "Epoch 00332: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 334/1500\n",
      "Epoch 00333: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 335/1500\n",
      "Epoch 00334: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 336/1500\n",
      "Epoch 00335: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 337/1500\n",
      "Epoch 00336: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 338/1500\n",
      "Epoch 00337: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 339/1500\n",
      "Epoch 00338: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 340/1500\n",
      "Epoch 00339: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 341/1500\n",
      "Epoch 00340: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 342/1500\n",
      "Epoch 00341: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 343/1500\n",
      "Epoch 00342: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 344/1500\n",
      "Epoch 00343: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 345/1500\n",
      "Epoch 00344: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 346/1500\n",
      "Epoch 00345: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 347/1500\n",
      "Epoch 00346: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 348/1500\n",
      "Epoch 00347: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 349/1500\n",
      "Epoch 00348: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 350/1500\n",
      "Epoch 00349: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 351/1500\n",
      "Epoch 00350: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 352/1500\n",
      "Epoch 00351: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 353/1500\n",
      "Epoch 00352: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 354/1500\n",
      "Epoch 00353: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 355/1500\n",
      "Epoch 00354: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 356/1500\n",
      "Epoch 00355: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 357/1500\n",
      "Epoch 00356: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 358/1500\n",
      "Epoch 00357: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 359/1500\n",
      "Epoch 00358: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6911 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 360/1500\n",
      "Epoch 00359: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 361/1500\n",
      "Epoch 00360: val_loss improved from 0.68476 to 0.68476, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 362/1500\n",
      "Epoch 00361: val_loss improved from 0.68476 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 363/1500\n",
      "Epoch 00362: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 364/1500\n",
      "Epoch 00363: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 365/1500\n",
      "Epoch 00364: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 366/1500\n",
      "Epoch 00365: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 367/1500\n",
      "Epoch 00366: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 368/1500\n",
      "Epoch 00367: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 369/1500\n",
      "Epoch 00368: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 370/1500\n",
      "Epoch 00369: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 371/1500\n",
      "Epoch 00370: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 372/1500\n",
      "Epoch 00371: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 373/1500\n",
      "Epoch 00372: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 374/1500\n",
      "Epoch 00373: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 375/1500\n",
      "Epoch 00374: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 376/1500\n",
      "Epoch 00375: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 377/1500\n",
      "Epoch 00376: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 378/1500\n",
      "Epoch 00377: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 379/1500\n",
      "Epoch 00378: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 380/1500\n",
      "Epoch 00379: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 381/1500\n",
      "Epoch 00380: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 382/1500\n",
      "Epoch 00381: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 383/1500\n",
      "Epoch 00382: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 384/1500\n",
      "Epoch 00383: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 385/1500\n",
      "Epoch 00384: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 386/1500\n",
      "Epoch 00385: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 387/1500\n",
      "Epoch 00386: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 388/1500\n",
      "Epoch 00387: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 389/1500\n",
      "Epoch 00388: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 390/1500\n",
      "Epoch 00389: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 391/1500\n",
      "Epoch 00390: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 392/1500\n",
      "Epoch 00391: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 393/1500\n",
      "Epoch 00392: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 394/1500\n",
      "Epoch 00393: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 395/1500\n",
      "Epoch 00394: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 396/1500\n",
      "Epoch 00395: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 397/1500\n",
      "Epoch 00396: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 398/1500\n",
      "Epoch 00397: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 399/1500\n",
      "Epoch 00398: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 400/1500\n",
      "Epoch 00399: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 401/1500\n",
      "Epoch 00400: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 402/1500\n",
      "Epoch 00401: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 403/1500\n",
      "Epoch 00402: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 404/1500\n",
      "Epoch 00403: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 405/1500\n",
      "Epoch 00404: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 406/1500\n",
      "Epoch 00405: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 407/1500\n",
      "Epoch 00406: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 408/1500\n",
      "Epoch 00407: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 409/1500\n",
      "Epoch 00408: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 410/1500\n",
      "Epoch 00409: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 411/1500\n",
      "Epoch 00410: val_loss improved from 0.68475 to 0.68475, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 412/1500\n",
      "Epoch 00411: val_loss improved from 0.68475 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 413/1500\n",
      "Epoch 00412: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 414/1500\n",
      "Epoch 00413: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 415/1500\n",
      "Epoch 00414: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 416/1500\n",
      "Epoch 00415: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 417/1500\n",
      "Epoch 00416: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 418/1500\n",
      "Epoch 00417: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 419/1500\n",
      "Epoch 00418: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 420/1500\n",
      "Epoch 00419: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 421/1500\n",
      "Epoch 00420: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 422/1500\n",
      "Epoch 00421: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 423/1500\n",
      "Epoch 00422: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 424/1500\n",
      "Epoch 00423: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 425/1500\n",
      "Epoch 00424: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 426/1500\n",
      "Epoch 00425: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 427/1500\n",
      "Epoch 00426: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 428/1500\n",
      "Epoch 00427: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 429/1500\n",
      "Epoch 00428: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 430/1500\n",
      "Epoch 00429: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 431/1500\n",
      "Epoch 00430: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 432/1500\n",
      "Epoch 00431: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 433/1500\n",
      "Epoch 00432: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 434/1500\n",
      "Epoch 00433: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 435/1500\n",
      "Epoch 00434: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 436/1500\n",
      "Epoch 00435: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 437/1500\n",
      "Epoch 00436: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 438/1500\n",
      "Epoch 00437: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 439/1500\n",
      "Epoch 00438: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 440/1500\n",
      "Epoch 00439: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 441/1500\n",
      "Epoch 00440: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 442/1500\n",
      "Epoch 00441: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 443/1500\n",
      "Epoch 00442: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 444/1500\n",
      "Epoch 00443: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 445/1500\n",
      "Epoch 00444: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 446/1500\n",
      "Epoch 00445: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 447/1500\n",
      "Epoch 00446: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 448/1500\n",
      "Epoch 00447: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 449/1500\n",
      "Epoch 00448: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 450/1500\n",
      "Epoch 00449: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 451/1500\n",
      "Epoch 00450: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 452/1500\n",
      "Epoch 00451: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 453/1500\n",
      "Epoch 00452: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 454/1500\n",
      "Epoch 00453: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 455/1500\n",
      "Epoch 00454: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 456/1500\n",
      "Epoch 00455: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 457/1500\n",
      "Epoch 00456: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 458/1500\n",
      "Epoch 00457: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 459/1500\n",
      "Epoch 00458: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 460/1500\n",
      "Epoch 00459: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 461/1500\n",
      "Epoch 00460: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 462/1500\n",
      "Epoch 00461: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 463/1500\n",
      "Epoch 00462: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 464/1500\n",
      "Epoch 00463: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 465/1500\n",
      "Epoch 00464: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 466/1500\n",
      "Epoch 00465: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 467/1500\n",
      "Epoch 00466: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 468/1500\n",
      "Epoch 00467: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 469/1500\n",
      "Epoch 00468: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 470/1500\n",
      "Epoch 00469: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 471/1500\n",
      "Epoch 00470: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 472/1500\n",
      "Epoch 00471: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 473/1500\n",
      "Epoch 00472: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 474/1500\n",
      "Epoch 00473: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 475/1500\n",
      "Epoch 00474: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 476/1500\n",
      "Epoch 00475: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 477/1500\n",
      "Epoch 00476: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 478/1500\n",
      "Epoch 00477: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 479/1500\n",
      "Epoch 00478: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 480/1500\n",
      "Epoch 00479: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 481/1500\n",
      "Epoch 00480: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 482/1500\n",
      "Epoch 00481: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 483/1500\n",
      "Epoch 00482: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 484/1500\n",
      "Epoch 00483: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 485/1500\n",
      "Epoch 00484: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 486/1500\n",
      "Epoch 00485: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 487/1500\n",
      "Epoch 00486: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 488/1500\n",
      "Epoch 00487: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 489/1500\n",
      "Epoch 00488: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 490/1500\n",
      "Epoch 00489: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 491/1500\n",
      "Epoch 00490: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 492/1500\n",
      "Epoch 00491: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 493/1500\n",
      "Epoch 00492: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 494/1500\n",
      "Epoch 00493: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 495/1500\n",
      "Epoch 00494: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 496/1500\n",
      "Epoch 00495: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 497/1500\n",
      "Epoch 00496: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 498/1500\n",
      "Epoch 00497: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 499/1500\n",
      "Epoch 00498: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 500/1500\n",
      "Epoch 00499: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 501/1500\n",
      "Epoch 00500: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 502/1500\n",
      "Epoch 00501: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 503/1500\n",
      "Epoch 00502: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 504/1500\n",
      "Epoch 00503: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 505/1500\n",
      "Epoch 00504: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 506/1500\n",
      "Epoch 00505: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 507/1500\n",
      "Epoch 00506: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 508/1500\n",
      "Epoch 00507: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 509/1500\n",
      "Epoch 00508: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 510/1500\n",
      "Epoch 00509: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 511/1500\n",
      "Epoch 00510: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 512/1500\n",
      "Epoch 00511: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 513/1500\n",
      "Epoch 00512: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 514/1500\n",
      "Epoch 00513: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 515/1500\n",
      "Epoch 00514: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 516/1500\n",
      "Epoch 00515: val_loss improved from 0.68474 to 0.68474, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 517/1500\n",
      "Epoch 00516: val_loss improved from 0.68474 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 518/1500\n",
      "Epoch 00517: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 519/1500\n",
      "Epoch 00518: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 520/1500\n",
      "Epoch 00519: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 521/1500\n",
      "Epoch 00520: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 522/1500\n",
      "Epoch 00521: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 523/1500\n",
      "Epoch 00522: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 524/1500\n",
      "Epoch 00523: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 525/1500\n",
      "Epoch 00524: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 526/1500\n",
      "Epoch 00525: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 527/1500\n",
      "Epoch 00526: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 528/1500\n",
      "Epoch 00527: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 529/1500\n",
      "Epoch 00528: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 530/1500\n",
      "Epoch 00529: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 531/1500\n",
      "Epoch 00530: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 532/1500\n",
      "Epoch 00531: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 533/1500\n",
      "Epoch 00532: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 534/1500\n",
      "Epoch 00533: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 535/1500\n",
      "Epoch 00534: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 536/1500\n",
      "Epoch 00535: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 537/1500\n",
      "Epoch 00536: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 538/1500\n",
      "Epoch 00537: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 539/1500\n",
      "Epoch 00538: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 540/1500\n",
      "Epoch 00539: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 541/1500\n",
      "Epoch 00540: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 542/1500\n",
      "Epoch 00541: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 543/1500\n",
      "Epoch 00542: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 544/1500\n",
      "Epoch 00543: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 545/1500\n",
      "Epoch 00544: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 546/1500\n",
      "Epoch 00545: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 547/1500\n",
      "Epoch 00546: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 548/1500\n",
      "Epoch 00547: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 549/1500\n",
      "Epoch 00548: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 550/1500\n",
      "Epoch 00549: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 551/1500\n",
      "Epoch 00550: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 552/1500\n",
      "Epoch 00551: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 553/1500\n",
      "Epoch 00552: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 554/1500\n",
      "Epoch 00553: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 555/1500\n",
      "Epoch 00554: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 556/1500\n",
      "Epoch 00555: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 557/1500\n",
      "Epoch 00556: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 558/1500\n",
      "Epoch 00557: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 559/1500\n",
      "Epoch 00558: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 560/1500\n",
      "Epoch 00559: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 561/1500\n",
      "Epoch 00560: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 562/1500\n",
      "Epoch 00561: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 563/1500\n",
      "Epoch 00562: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 564/1500\n",
      "Epoch 00563: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 565/1500\n",
      "Epoch 00564: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 566/1500\n",
      "Epoch 00565: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 567/1500\n",
      "Epoch 00566: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 568/1500\n",
      "Epoch 00567: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 569/1500\n",
      "Epoch 00568: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 570/1500\n",
      "Epoch 00569: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 571/1500\n",
      "Epoch 00570: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 572/1500\n",
      "Epoch 00571: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 573/1500\n",
      "Epoch 00572: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 574/1500\n",
      "Epoch 00573: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 575/1500\n",
      "Epoch 00574: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 576/1500\n",
      "Epoch 00575: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 577/1500\n",
      "Epoch 00576: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 578/1500\n",
      "Epoch 00577: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 579/1500\n",
      "Epoch 00578: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 580/1500\n",
      "Epoch 00579: val_loss improved from 0.68473 to 0.68473, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 581/1500\n",
      "Epoch 00580: val_loss improved from 0.68473 to 0.68472, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 582/1500\n",
      "Epoch 00581: val_loss improved from 0.68472 to 0.68472, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 583/1500\n",
      "Epoch 00582: val_loss improved from 0.68472 to 0.68472, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 584/1500\n",
      "Epoch 00583: val_loss improved from 0.68472 to 0.68472, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 585/1500\n",
      "Epoch 00584: val_loss improved from 0.68472 to 0.68472, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 586/1500\n",
      "Epoch 00585: val_loss improved from 0.68472 to 0.68472, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 587/1500\n",
      "Epoch 00586: val_loss improved from 0.68472 to 0.68472, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 588/1500\n",
      "Epoch 00587: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 589/1500\n",
      "Epoch 00588: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 590/1500\n",
      "Epoch 00589: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 591/1500\n",
      "Epoch 00590: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 592/1500\n",
      "Epoch 00591: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 593/1500\n",
      "Epoch 00592: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 594/1500\n",
      "Epoch 00593: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 595/1500\n",
      "Epoch 00594: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 596/1500\n",
      "Epoch 00595: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 597/1500\n",
      "Epoch 00596: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 598/1500\n",
      "Epoch 00597: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 599/1500\n",
      "Epoch 00598: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 600/1500\n",
      "Epoch 00599: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 601/1500\n",
      "Epoch 00600: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 602/1500\n",
      "Epoch 00601: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 603/1500\n",
      "Epoch 00602: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 604/1500\n",
      "Epoch 00603: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 605/1500\n",
      "Epoch 00604: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 606/1500\n",
      "Epoch 00605: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 607/1500\n",
      "Epoch 00606: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 608/1500\n",
      "Epoch 00607: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 609/1500\n",
      "Epoch 00608: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 610/1500\n",
      "Epoch 00609: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 611/1500\n",
      "Epoch 00610: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 612/1500\n",
      "Epoch 00611: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 613/1500\n",
      "Epoch 00612: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 614/1500\n",
      "Epoch 00613: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 615/1500\n",
      "Epoch 00614: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 616/1500\n",
      "Epoch 00615: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 617/1500\n",
      "Epoch 00616: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 618/1500\n",
      "Epoch 00617: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 619/1500\n",
      "Epoch 00618: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 620/1500\n",
      "Epoch 00619: val_loss improved from 0.68472 to 0.68472, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 621/1500\n",
      "Epoch 00620: val_loss improved from 0.68472 to 0.68472, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 622/1500\n",
      "Epoch 00621: val_loss improved from 0.68472 to 0.68472, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 623/1500\n",
      "Epoch 00622: val_loss improved from 0.68472 to 0.68472, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 624/1500\n",
      "Epoch 00623: val_loss improved from 0.68472 to 0.68472, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 625/1500\n",
      "Epoch 00624: val_loss improved from 0.68472 to 0.68472, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 626/1500\n",
      "Epoch 00625: val_loss improved from 0.68472 to 0.68472, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 627/1500\n",
      "Epoch 00626: val_loss improved from 0.68472 to 0.68471, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 628/1500\n",
      "Epoch 00627: val_loss improved from 0.68471 to 0.68471, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 629/1500\n",
      "Epoch 00628: val_loss improved from 0.68471 to 0.68471, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 630/1500\n",
      "Epoch 00629: val_loss improved from 0.68471 to 0.68471, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 631/1500\n",
      "Epoch 00630: val_loss improved from 0.68471 to 0.68471, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 632/1500\n",
      "Epoch 00631: val_loss improved from 0.68471 to 0.68471, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 633/1500\n",
      "Epoch 00632: val_loss improved from 0.68471 to 0.68471, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 634/1500\n",
      "Epoch 00633: val_loss improved from 0.68471 to 0.68471, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 635/1500\n",
      "Epoch 00634: val_loss improved from 0.68471 to 0.68471, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 636/1500\n",
      "Epoch 00635: val_loss improved from 0.68471 to 0.68471, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 637/1500\n",
      "Epoch 00636: val_loss improved from 0.68471 to 0.68471, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 638/1500\n",
      "Epoch 00637: val_loss improved from 0.68471 to 0.68471, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 639/1500\n",
      "Epoch 00638: val_loss improved from 0.68471 to 0.68471, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 640/1500\n",
      "Epoch 00639: val_loss improved from 0.68471 to 0.68471, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 641/1500\n",
      "Epoch 00640: val_loss improved from 0.68471 to 0.68470, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 642/1500\n",
      "Epoch 00641: val_loss improved from 0.68470 to 0.68470, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 643/1500\n",
      "Epoch 00642: val_loss improved from 0.68470 to 0.68470, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 644/1500\n",
      "Epoch 00643: val_loss improved from 0.68470 to 0.68470, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 645/1500\n",
      "Epoch 00644: val_loss improved from 0.68470 to 0.68470, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 646/1500\n",
      "Epoch 00645: val_loss improved from 0.68470 to 0.68470, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 647/1500\n",
      "Epoch 00646: val_loss improved from 0.68470 to 0.68470, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 648/1500\n",
      "Epoch 00647: val_loss improved from 0.68470 to 0.68470, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 649/1500\n",
      "Epoch 00648: val_loss improved from 0.68470 to 0.68470, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 650/1500\n",
      "Epoch 00649: val_loss improved from 0.68470 to 0.68470, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 651/1500\n",
      "Epoch 00650: val_loss improved from 0.68470 to 0.68470, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 652/1500\n",
      "Epoch 00651: val_loss improved from 0.68470 to 0.68470, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 653/1500\n",
      "Epoch 00652: val_loss improved from 0.68470 to 0.68470, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 654/1500\n",
      "Epoch 00653: val_loss improved from 0.68470 to 0.68470, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 655/1500\n",
      "Epoch 00654: val_loss improved from 0.68470 to 0.68470, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 656/1500\n",
      "Epoch 00655: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 657/1500\n",
      "Epoch 00656: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 658/1500\n",
      "Epoch 00657: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 659/1500\n",
      "Epoch 00658: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 660/1500\n",
      "Epoch 00659: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 661/1500\n",
      "Epoch 00660: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 662/1500\n",
      "Epoch 00661: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 663/1500\n",
      "Epoch 00662: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 664/1500\n",
      "Epoch 00663: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 665/1500\n",
      "Epoch 00664: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 666/1500\n",
      "Epoch 00665: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 667/1500\n",
      "Epoch 00666: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 668/1500\n",
      "Epoch 00667: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 669/1500\n",
      "Epoch 00668: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 670/1500\n",
      "Epoch 00669: val_loss improved from 0.68470 to 0.68470, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 671/1500\n",
      "Epoch 00670: val_loss improved from 0.68470 to 0.68469, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 672/1500\n",
      "Epoch 00671: val_loss improved from 0.68469 to 0.68469, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 673/1500\n",
      "Epoch 00672: val_loss improved from 0.68469 to 0.68469, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 674/1500\n",
      "Epoch 00673: val_loss improved from 0.68469 to 0.68468, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 675/1500\n",
      "Epoch 00674: val_loss improved from 0.68468 to 0.68468, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 676/1500\n",
      "Epoch 00675: val_loss improved from 0.68468 to 0.68468, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 677/1500\n",
      "Epoch 00676: val_loss improved from 0.68468 to 0.68467, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 678/1500\n",
      "Epoch 00677: val_loss improved from 0.68467 to 0.68467, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 679/1500\n",
      "Epoch 00678: val_loss improved from 0.68467 to 0.68467, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 680/1500\n",
      "Epoch 00679: val_loss improved from 0.68467 to 0.68467, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 681/1500\n",
      "Epoch 00680: val_loss improved from 0.68467 to 0.68466, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 682/1500\n",
      "Epoch 00681: val_loss improved from 0.68466 to 0.68466, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 683/1500\n",
      "Epoch 00682: val_loss improved from 0.68466 to 0.68466, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 684/1500\n",
      "Epoch 00683: val_loss improved from 0.68466 to 0.68466, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 685/1500\n",
      "Epoch 00684: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 686/1500\n",
      "Epoch 00685: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 687/1500\n",
      "Epoch 00686: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 688/1500\n",
      "Epoch 00687: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 689/1500\n",
      "Epoch 00688: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 690/1500\n",
      "Epoch 00689: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 691/1500\n",
      "Epoch 00690: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 692/1500\n",
      "Epoch 00691: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 693/1500\n",
      "Epoch 00692: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 694/1500\n",
      "Epoch 00693: val_loss improved from 0.68466 to 0.68466, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 695/1500\n",
      "Epoch 00694: val_loss improved from 0.68466 to 0.68466, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 696/1500\n",
      "Epoch 00695: val_loss improved from 0.68466 to 0.68466, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 697/1500\n",
      "Epoch 00696: val_loss improved from 0.68466 to 0.68466, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 698/1500\n",
      "Epoch 00697: val_loss improved from 0.68466 to 0.68465, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 699/1500\n",
      "Epoch 00698: val_loss improved from 0.68465 to 0.68465, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 700/1500\n",
      "Epoch 00699: val_loss improved from 0.68465 to 0.68465, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 701/1500\n",
      "Epoch 00700: val_loss improved from 0.68465 to 0.68465, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 702/1500\n",
      "Epoch 00701: val_loss improved from 0.68465 to 0.68465, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 703/1500\n",
      "Epoch 00702: val_loss improved from 0.68465 to 0.68465, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 704/1500\n",
      "Epoch 00703: val_loss improved from 0.68465 to 0.68464, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 705/1500\n",
      "Epoch 00704: val_loss improved from 0.68464 to 0.68464, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 706/1500\n",
      "Epoch 00705: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 707/1500\n",
      "Epoch 00706: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 708/1500\n",
      "Epoch 00707: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 709/1500\n",
      "Epoch 00708: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 710/1500\n",
      "Epoch 00709: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 711/1500\n",
      "Epoch 00710: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 712/1500\n",
      "Epoch 00711: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 713/1500\n",
      "Epoch 00712: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 714/1500\n",
      "Epoch 00713: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 715/1500\n",
      "Epoch 00714: val_loss improved from 0.68464 to 0.68464, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 716/1500\n",
      "Epoch 00715: val_loss improved from 0.68464 to 0.68464, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 717/1500\n",
      "Epoch 00716: val_loss improved from 0.68464 to 0.68464, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 718/1500\n",
      "Epoch 00717: val_loss improved from 0.68464 to 0.68464, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 719/1500\n",
      "Epoch 00718: val_loss improved from 0.68464 to 0.68464, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 720/1500\n",
      "Epoch 00719: val_loss improved from 0.68464 to 0.68464, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 721/1500\n",
      "Epoch 00720: val_loss improved from 0.68464 to 0.68464, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 722/1500\n",
      "Epoch 00721: val_loss improved from 0.68464 to 0.68464, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 723/1500\n",
      "Epoch 00722: val_loss improved from 0.68464 to 0.68464, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 724/1500\n",
      "Epoch 00723: val_loss improved from 0.68464 to 0.68464, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 725/1500\n",
      "Epoch 00724: val_loss improved from 0.68464 to 0.68464, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 726/1500\n",
      "Epoch 00725: val_loss improved from 0.68464 to 0.68463, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 727/1500\n",
      "Epoch 00726: val_loss improved from 0.68463 to 0.68463, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 728/1500\n",
      "Epoch 00727: val_loss improved from 0.68463 to 0.68463, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 729/1500\n",
      "Epoch 00728: val_loss improved from 0.68463 to 0.68463, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 730/1500\n",
      "Epoch 00729: val_loss improved from 0.68463 to 0.68463, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 731/1500\n",
      "Epoch 00730: val_loss improved from 0.68463 to 0.68463, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 732/1500\n",
      "Epoch 00731: val_loss improved from 0.68463 to 0.68463, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 733/1500\n",
      "Epoch 00732: val_loss improved from 0.68463 to 0.68463, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 734/1500\n",
      "Epoch 00733: val_loss improved from 0.68463 to 0.68463, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 735/1500\n",
      "Epoch 00734: val_loss improved from 0.68463 to 0.68463, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 736/1500\n",
      "Epoch 00735: val_loss improved from 0.68463 to 0.68463, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 737/1500\n",
      "Epoch 00736: val_loss improved from 0.68463 to 0.68463, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 738/1500\n",
      "Epoch 00737: val_loss improved from 0.68463 to 0.68463, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 739/1500\n",
      "Epoch 00738: val_loss improved from 0.68463 to 0.68463, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 740/1500\n",
      "Epoch 00739: val_loss improved from 0.68463 to 0.68463, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 741/1500\n",
      "Epoch 00740: val_loss improved from 0.68463 to 0.68462, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 742/1500\n",
      "Epoch 00741: val_loss improved from 0.68462 to 0.68462, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 743/1500\n",
      "Epoch 00742: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 744/1500\n",
      "Epoch 00743: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 745/1500\n",
      "Epoch 00744: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 746/1500\n",
      "Epoch 00745: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 747/1500\n",
      "Epoch 00746: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 748/1500\n",
      "Epoch 00747: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 749/1500\n",
      "Epoch 00748: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 750/1500\n",
      "Epoch 00749: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 751/1500\n",
      "Epoch 00750: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 752/1500\n",
      "Epoch 00751: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 753/1500\n",
      "Epoch 00752: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 754/1500\n",
      "Epoch 00753: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 755/1500\n",
      "Epoch 00754: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6910 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 756/1500\n",
      "Epoch 00755: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 757/1500\n",
      "Epoch 00756: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 758/1500\n",
      "Epoch 00757: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 759/1500\n",
      "Epoch 00758: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 760/1500\n",
      "Epoch 00759: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 761/1500\n",
      "Epoch 00760: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 762/1500\n",
      "Epoch 00761: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 763/1500\n",
      "Epoch 00762: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 764/1500\n",
      "Epoch 00763: val_loss improved from 0.68462 to 0.68462, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 765/1500\n",
      "Epoch 00764: val_loss improved from 0.68462 to 0.68462, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 766/1500\n",
      "Epoch 00765: val_loss improved from 0.68462 to 0.68462, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 767/1500\n",
      "Epoch 00766: val_loss improved from 0.68462 to 0.68461, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 768/1500\n",
      "Epoch 00767: val_loss improved from 0.68461 to 0.68461, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 769/1500\n",
      "Epoch 00768: val_loss improved from 0.68461 to 0.68461, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 770/1500\n",
      "Epoch 00769: val_loss improved from 0.68461 to 0.68461, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 771/1500\n",
      "Epoch 00770: val_loss improved from 0.68461 to 0.68460, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 772/1500\n",
      "Epoch 00771: val_loss improved from 0.68460 to 0.68460, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 773/1500\n",
      "Epoch 00772: val_loss improved from 0.68460 to 0.68460, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 774/1500\n",
      "Epoch 00773: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 775/1500\n",
      "Epoch 00774: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 776/1500\n",
      "Epoch 00775: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 777/1500\n",
      "Epoch 00776: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 778/1500\n",
      "Epoch 00777: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 779/1500\n",
      "Epoch 00778: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 780/1500\n",
      "Epoch 00779: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 781/1500\n",
      "Epoch 00780: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 782/1500\n",
      "Epoch 00781: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 783/1500\n",
      "Epoch 00782: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 784/1500\n",
      "Epoch 00783: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 785/1500\n",
      "Epoch 00784: val_loss improved from 0.68460 to 0.68460, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 786/1500\n",
      "Epoch 00785: val_loss improved from 0.68460 to 0.68460, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 787/1500\n",
      "Epoch 00786: val_loss improved from 0.68460 to 0.68460, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 788/1500\n",
      "Epoch 00787: val_loss improved from 0.68460 to 0.68459, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 789/1500\n",
      "Epoch 00788: val_loss improved from 0.68459 to 0.68459, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 790/1500\n",
      "Epoch 00789: val_loss improved from 0.68459 to 0.68459, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 791/1500\n",
      "Epoch 00790: val_loss improved from 0.68459 to 0.68459, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 792/1500\n",
      "Epoch 00791: val_loss improved from 0.68459 to 0.68459, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 793/1500\n",
      "Epoch 00792: val_loss improved from 0.68459 to 0.68459, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 794/1500\n",
      "Epoch 00793: val_loss improved from 0.68459 to 0.68459, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 795/1500\n",
      "Epoch 00794: val_loss improved from 0.68459 to 0.68459, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 796/1500\n",
      "Epoch 00795: val_loss improved from 0.68459 to 0.68458, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 797/1500\n",
      "Epoch 00796: val_loss improved from 0.68458 to 0.68458, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 798/1500\n",
      "Epoch 00797: val_loss improved from 0.68458 to 0.68458, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 799/1500\n",
      "Epoch 00798: val_loss improved from 0.68458 to 0.68458, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 800/1500\n",
      "Epoch 00799: val_loss improved from 0.68458 to 0.68458, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 801/1500\n",
      "Epoch 00800: val_loss improved from 0.68458 to 0.68458, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 802/1500\n",
      "Epoch 00801: val_loss improved from 0.68458 to 0.68458, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 803/1500\n",
      "Epoch 00802: val_loss improved from 0.68458 to 0.68458, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 804/1500\n",
      "Epoch 00803: val_loss improved from 0.68458 to 0.68458, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 805/1500\n",
      "Epoch 00804: val_loss improved from 0.68458 to 0.68458, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 806/1500\n",
      "Epoch 00805: val_loss improved from 0.68458 to 0.68458, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 807/1500\n",
      "Epoch 00806: val_loss improved from 0.68458 to 0.68458, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 808/1500\n",
      "Epoch 00807: val_loss improved from 0.68458 to 0.68458, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 809/1500\n",
      "Epoch 00808: val_loss improved from 0.68458 to 0.68458, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 810/1500\n",
      "Epoch 00809: val_loss improved from 0.68458 to 0.68457, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 811/1500\n",
      "Epoch 00810: val_loss improved from 0.68457 to 0.68457, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 812/1500\n",
      "Epoch 00811: val_loss improved from 0.68457 to 0.68457, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 813/1500\n",
      "Epoch 00812: val_loss improved from 0.68457 to 0.68457, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 814/1500\n",
      "Epoch 00813: val_loss improved from 0.68457 to 0.68457, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 815/1500\n",
      "Epoch 00814: val_loss improved from 0.68457 to 0.68457, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 816/1500\n",
      "Epoch 00815: val_loss improved from 0.68457 to 0.68457, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 817/1500\n",
      "Epoch 00816: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 818/1500\n",
      "Epoch 00817: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 819/1500\n",
      "Epoch 00818: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 820/1500\n",
      "Epoch 00819: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 821/1500\n",
      "Epoch 00820: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 822/1500\n",
      "Epoch 00821: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 823/1500\n",
      "Epoch 00822: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 824/1500\n",
      "Epoch 00823: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 825/1500\n",
      "Epoch 00824: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 826/1500\n",
      "Epoch 00825: val_loss improved from 0.68457 to 0.68456, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 827/1500\n",
      "Epoch 00826: val_loss improved from 0.68456 to 0.68456, saving model to saved_models/weights.test_run.hdf5\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 828/1500\n",
      "Epoch 00827: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 829/1500\n",
      "Epoch 00828: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 830/1500\n",
      "Epoch 00829: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 831/1500\n",
      "Epoch 00830: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 832/1500\n",
      "Epoch 00831: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 833/1500\n",
      "Epoch 00832: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 834/1500\n",
      "Epoch 00833: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 835/1500\n",
      "Epoch 00834: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 836/1500\n",
      "Epoch 00835: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 837/1500\n",
      "Epoch 00836: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 838/1500\n",
      "Epoch 00837: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 839/1500\n",
      "Epoch 00838: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 840/1500\n",
      "Epoch 00839: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 841/1500\n",
      "Epoch 00840: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 842/1500\n",
      "Epoch 00841: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 843/1500\n",
      "Epoch 00842: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 844/1500\n",
      "Epoch 00843: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 845/1500\n",
      "Epoch 00844: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 846/1500\n",
      "Epoch 00845: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 847/1500\n",
      "Epoch 00846: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 848/1500\n",
      "Epoch 00847: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 849/1500\n",
      "Epoch 00848: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 850/1500\n",
      "Epoch 00849: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 851/1500\n",
      "Epoch 00850: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 852/1500\n",
      "Epoch 00851: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 853/1500\n",
      "Epoch 00852: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 854/1500\n",
      "Epoch 00853: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 855/1500\n",
      "Epoch 00854: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 856/1500\n",
      "Epoch 00855: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 857/1500\n",
      "Epoch 00856: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 858/1500\n",
      "Epoch 00857: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6909 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 859/1500\n",
      "Epoch 00858: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 860/1500\n",
      "Epoch 00859: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 861/1500\n",
      "Epoch 00860: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 862/1500\n",
      "Epoch 00861: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 863/1500\n",
      "Epoch 00862: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 864/1500\n",
      "Epoch 00863: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 865/1500\n",
      "Epoch 00864: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 866/1500\n",
      "Epoch 00865: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 867/1500\n",
      "Epoch 00866: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 868/1500\n",
      "Epoch 00867: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 869/1500\n",
      "Epoch 00868: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 870/1500\n",
      "Epoch 00869: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 871/1500\n",
      "Epoch 00870: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 872/1500\n",
      "Epoch 00871: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 873/1500\n",
      "Epoch 00872: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 874/1500\n",
      "Epoch 00873: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 875/1500\n",
      "Epoch 00874: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 876/1500\n",
      "Epoch 00875: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 877/1500\n",
      "Epoch 00876: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 878/1500\n",
      "Epoch 00877: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 879/1500\n",
      "Epoch 00878: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 880/1500\n",
      "Epoch 00879: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 881/1500\n",
      "Epoch 00880: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 882/1500\n",
      "Epoch 00881: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 883/1500\n",
      "Epoch 00882: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 884/1500\n",
      "Epoch 00883: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 885/1500\n",
      "Epoch 00884: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 886/1500\n",
      "Epoch 00885: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 887/1500\n",
      "Epoch 00886: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 888/1500\n",
      "Epoch 00887: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 889/1500\n",
      "Epoch 00888: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 890/1500\n",
      "Epoch 00889: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 891/1500\n",
      "Epoch 00890: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 892/1500\n",
      "Epoch 00891: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 893/1500\n",
      "Epoch 00892: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 894/1500\n",
      "Epoch 00893: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 895/1500\n",
      "Epoch 00894: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 896/1500\n",
      "Epoch 00895: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 897/1500\n",
      "Epoch 00896: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 898/1500\n",
      "Epoch 00897: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 899/1500\n",
      "Epoch 00898: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 900/1500\n",
      "Epoch 00899: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 901/1500\n",
      "Epoch 00900: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 902/1500\n",
      "Epoch 00901: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 903/1500\n",
      "Epoch 00902: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 904/1500\n",
      "Epoch 00903: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 905/1500\n",
      "Epoch 00904: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 906/1500\n",
      "Epoch 00905: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 907/1500\n",
      "Epoch 00906: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 908/1500\n",
      "Epoch 00907: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 909/1500\n",
      "Epoch 00908: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 910/1500\n",
      "Epoch 00909: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 911/1500\n",
      "Epoch 00910: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 912/1500\n",
      "Epoch 00911: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 913/1500\n",
      "Epoch 00912: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 914/1500\n",
      "Epoch 00913: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 915/1500\n",
      "Epoch 00914: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 916/1500\n",
      "Epoch 00915: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 917/1500\n",
      "Epoch 00916: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 918/1500\n",
      "Epoch 00917: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 919/1500\n",
      "Epoch 00918: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 920/1500\n",
      "Epoch 00919: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 921/1500\n",
      "Epoch 00920: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 922/1500\n",
      "Epoch 00921: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 923/1500\n",
      "Epoch 00922: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 924/1500\n",
      "Epoch 00923: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 925/1500\n",
      "Epoch 00924: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6846 - val_acc: 0.5729\n",
      "Epoch 926/1500\n",
      "Epoch 00925: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 927/1500\n",
      "Epoch 00926: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 928/1500\n",
      "Epoch 00927: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 929/1500\n",
      "Epoch 00928: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 930/1500\n",
      "Epoch 00929: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 931/1500\n",
      "Epoch 00930: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 932/1500\n",
      "Epoch 00931: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 933/1500\n",
      "Epoch 00932: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 934/1500\n",
      "Epoch 00933: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 935/1500\n",
      "Epoch 00934: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 936/1500\n",
      "Epoch 00935: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 937/1500\n",
      "Epoch 00936: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 938/1500\n",
      "Epoch 00937: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 939/1500\n",
      "Epoch 00938: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 940/1500\n",
      "Epoch 00939: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 941/1500\n",
      "Epoch 00940: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 942/1500\n",
      "Epoch 00941: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 943/1500\n",
      "Epoch 00942: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 944/1500\n",
      "Epoch 00943: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 945/1500\n",
      "Epoch 00944: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 946/1500\n",
      "Epoch 00945: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 947/1500\n",
      "Epoch 00946: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 948/1500\n",
      "Epoch 00947: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 949/1500\n",
      "Epoch 00948: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 950/1500\n",
      "Epoch 00949: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 951/1500\n",
      "Epoch 00950: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 952/1500\n",
      "Epoch 00951: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 953/1500\n",
      "Epoch 00952: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 954/1500\n",
      "Epoch 00953: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 955/1500\n",
      "Epoch 00954: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 956/1500\n",
      "Epoch 00955: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 957/1500\n",
      "Epoch 00956: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 958/1500\n",
      "Epoch 00957: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 959/1500\n",
      "Epoch 00958: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 960/1500\n",
      "Epoch 00959: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6908 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 961/1500\n",
      "Epoch 00960: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 962/1500\n",
      "Epoch 00961: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 963/1500\n",
      "Epoch 00962: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 964/1500\n",
      "Epoch 00963: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 965/1500\n",
      "Epoch 00964: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 966/1500\n",
      "Epoch 00965: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 967/1500\n",
      "Epoch 00966: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 968/1500\n",
      "Epoch 00967: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 969/1500\n",
      "Epoch 00968: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 970/1500\n",
      "Epoch 00969: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 971/1500\n",
      "Epoch 00970: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 972/1500\n",
      "Epoch 00971: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 973/1500\n",
      "Epoch 00972: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 974/1500\n",
      "Epoch 00973: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 975/1500\n",
      "Epoch 00974: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 976/1500\n",
      "Epoch 00975: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 977/1500\n",
      "Epoch 00976: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 978/1500\n",
      "Epoch 00977: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 979/1500\n",
      "Epoch 00978: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 980/1500\n",
      "Epoch 00979: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 981/1500\n",
      "Epoch 00980: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 982/1500\n",
      "Epoch 00981: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6847 - val_acc: 0.5729\n",
      "Epoch 983/1500\n",
      "Epoch 00982: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 984/1500\n",
      "Epoch 00983: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 985/1500\n",
      "Epoch 00984: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 986/1500\n",
      "Epoch 00985: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 987/1500\n",
      "Epoch 00986: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 988/1500\n",
      "Epoch 00987: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 989/1500\n",
      "Epoch 00988: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 990/1500\n",
      "Epoch 00989: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 991/1500\n",
      "Epoch 00990: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 992/1500\n",
      "Epoch 00991: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 993/1500\n",
      "Epoch 00992: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 994/1500\n",
      "Epoch 00993: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 995/1500\n",
      "Epoch 00994: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 996/1500\n",
      "Epoch 00995: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 997/1500\n",
      "Epoch 00996: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 998/1500\n",
      "Epoch 00997: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 999/1500\n",
      "Epoch 00998: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1000/1500\n",
      "Epoch 00999: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1001/1500\n",
      "Epoch 01000: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1002/1500\n",
      "Epoch 01001: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1003/1500\n",
      "Epoch 01002: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1004/1500\n",
      "Epoch 01003: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1005/1500\n",
      "Epoch 01004: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1006/1500\n",
      "Epoch 01005: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1007/1500\n",
      "Epoch 01006: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1008/1500\n",
      "Epoch 01007: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1009/1500\n",
      "Epoch 01008: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1010/1500\n",
      "Epoch 01009: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1011/1500\n",
      "Epoch 01010: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1012/1500\n",
      "Epoch 01011: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1013/1500\n",
      "Epoch 01012: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1014/1500\n",
      "Epoch 01013: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1015/1500\n",
      "Epoch 01014: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1016/1500\n",
      "Epoch 01015: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1017/1500\n",
      "Epoch 01016: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1018/1500\n",
      "Epoch 01017: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1019/1500\n",
      "Epoch 01018: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1020/1500\n",
      "Epoch 01019: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1021/1500\n",
      "Epoch 01020: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1022/1500\n",
      "Epoch 01021: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1023/1500\n",
      "Epoch 01022: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1024/1500\n",
      "Epoch 01023: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1025/1500\n",
      "Epoch 01024: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1026/1500\n",
      "Epoch 01025: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1027/1500\n",
      "Epoch 01026: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6848 - val_acc: 0.5729\n",
      "Epoch 1028/1500\n",
      "Epoch 01027: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1029/1500\n",
      "Epoch 01028: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1030/1500\n",
      "Epoch 01029: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1031/1500\n",
      "Epoch 01030: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1032/1500\n",
      "Epoch 01031: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1033/1500\n",
      "Epoch 01032: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1034/1500\n",
      "Epoch 01033: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1035/1500\n",
      "Epoch 01034: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1036/1500\n",
      "Epoch 01035: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1037/1500\n",
      "Epoch 01036: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1038/1500\n",
      "Epoch 01037: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1039/1500\n",
      "Epoch 01038: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1040/1500\n",
      "Epoch 01039: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1041/1500\n",
      "Epoch 01040: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1042/1500\n",
      "Epoch 01041: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1043/1500\n",
      "Epoch 01042: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1044/1500\n",
      "Epoch 01043: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1045/1500\n",
      "Epoch 01044: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1046/1500\n",
      "Epoch 01045: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1047/1500\n",
      "Epoch 01046: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1048/1500\n",
      "Epoch 01047: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1049/1500\n",
      "Epoch 01048: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1050/1500\n",
      "Epoch 01049: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1051/1500\n",
      "Epoch 01050: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1052/1500\n",
      "Epoch 01051: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1053/1500\n",
      "Epoch 01052: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1054/1500\n",
      "Epoch 01053: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1055/1500\n",
      "Epoch 01054: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1056/1500\n",
      "Epoch 01055: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1057/1500\n",
      "Epoch 01056: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1058/1500\n",
      "Epoch 01057: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1059/1500\n",
      "Epoch 01058: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6849 - val_acc: 0.5729\n",
      "Epoch 1060/1500\n",
      "Epoch 01059: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1061/1500\n",
      "Epoch 01060: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6907 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1062/1500\n",
      "Epoch 01061: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1063/1500\n",
      "Epoch 01062: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1064/1500\n",
      "Epoch 01063: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1065/1500\n",
      "Epoch 01064: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1066/1500\n",
      "Epoch 01065: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1067/1500\n",
      "Epoch 01066: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1068/1500\n",
      "Epoch 01067: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1069/1500\n",
      "Epoch 01068: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1070/1500\n",
      "Epoch 01069: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1071/1500\n",
      "Epoch 01070: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1072/1500\n",
      "Epoch 01071: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1073/1500\n",
      "Epoch 01072: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1074/1500\n",
      "Epoch 01073: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1075/1500\n",
      "Epoch 01074: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1076/1500\n",
      "Epoch 01075: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1077/1500\n",
      "Epoch 01076: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1078/1500\n",
      "Epoch 01077: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1079/1500\n",
      "Epoch 01078: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1080/1500\n",
      "Epoch 01079: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1081/1500\n",
      "Epoch 01080: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1082/1500\n",
      "Epoch 01081: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1083/1500\n",
      "Epoch 01082: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1084/1500\n",
      "Epoch 01083: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6850 - val_acc: 0.5729\n",
      "Epoch 1085/1500\n",
      "Epoch 01084: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1086/1500\n",
      "Epoch 01085: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1087/1500\n",
      "Epoch 01086: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1088/1500\n",
      "Epoch 01087: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1089/1500\n",
      "Epoch 01088: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1090/1500\n",
      "Epoch 01089: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1091/1500\n",
      "Epoch 01090: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1092/1500\n",
      "Epoch 01091: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1093/1500\n",
      "Epoch 01092: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1094/1500\n",
      "Epoch 01093: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1095/1500\n",
      "Epoch 01094: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1096/1500\n",
      "Epoch 01095: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1097/1500\n",
      "Epoch 01096: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1098/1500\n",
      "Epoch 01097: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1099/1500\n",
      "Epoch 01098: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1100/1500\n",
      "Epoch 01099: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1101/1500\n",
      "Epoch 01100: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1102/1500\n",
      "Epoch 01101: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1103/1500\n",
      "Epoch 01102: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1104/1500\n",
      "Epoch 01103: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1105/1500\n",
      "Epoch 01104: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1106/1500\n",
      "Epoch 01105: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1107/1500\n",
      "Epoch 01106: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1108/1500\n",
      "Epoch 01107: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1109/1500\n",
      "Epoch 01108: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1110/1500\n",
      "Epoch 01109: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6851 - val_acc: 0.5729\n",
      "Epoch 1111/1500\n",
      "Epoch 01110: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1112/1500\n",
      "Epoch 01111: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1113/1500\n",
      "Epoch 01112: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1114/1500\n",
      "Epoch 01113: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1115/1500\n",
      "Epoch 01114: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1116/1500\n",
      "Epoch 01115: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1117/1500\n",
      "Epoch 01116: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1118/1500\n",
      "Epoch 01117: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1119/1500\n",
      "Epoch 01118: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1120/1500\n",
      "Epoch 01119: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1121/1500\n",
      "Epoch 01120: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1122/1500\n",
      "Epoch 01121: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1123/1500\n",
      "Epoch 01122: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1124/1500\n",
      "Epoch 01123: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1125/1500\n",
      "Epoch 01124: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1126/1500\n",
      "Epoch 01125: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1127/1500\n",
      "Epoch 01126: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1128/1500\n",
      "Epoch 01127: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1129/1500\n",
      "Epoch 01128: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1130/1500\n",
      "Epoch 01129: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1131/1500\n",
      "Epoch 01130: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1132/1500\n",
      "Epoch 01131: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1133/1500\n",
      "Epoch 01132: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1134/1500\n",
      "Epoch 01133: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1135/1500\n",
      "Epoch 01134: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6852 - val_acc: 0.5729\n",
      "Epoch 1136/1500\n",
      "Epoch 01135: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6853 - val_acc: 0.5729\n",
      "Epoch 1137/1500\n",
      "Epoch 01136: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6853 - val_acc: 0.5729\n",
      "Epoch 1138/1500\n",
      "Epoch 01137: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6853 - val_acc: 0.5729\n",
      "Epoch 1139/1500\n",
      "Epoch 01138: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6853 - val_acc: 0.5729\n",
      "Epoch 1140/1500\n",
      "Epoch 01139: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6853 - val_acc: 0.5729\n",
      "Epoch 1141/1500\n",
      "Epoch 01140: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6853 - val_acc: 0.5729\n",
      "Epoch 1142/1500\n",
      "Epoch 01141: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6853 - val_acc: 0.5729\n",
      "Epoch 1143/1500\n",
      "Epoch 01142: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6853 - val_acc: 0.5729\n",
      "Epoch 1144/1500\n",
      "Epoch 01143: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6853 - val_acc: 0.5729\n",
      "Epoch 1145/1500\n",
      "Epoch 01144: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6853 - val_acc: 0.5729\n",
      "Epoch 1146/1500\n",
      "Epoch 01145: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6853 - val_acc: 0.5729\n",
      "Epoch 1147/1500\n",
      "Epoch 01146: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6853 - val_acc: 0.5729\n",
      "Epoch 1148/1500\n",
      "Epoch 01147: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6853 - val_acc: 0.5729\n",
      "Epoch 1149/1500\n",
      "Epoch 01148: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6853 - val_acc: 0.5729\n",
      "Epoch 1150/1500\n",
      "Epoch 01149: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6853 - val_acc: 0.5729\n",
      "Epoch 1151/1500\n",
      "Epoch 01150: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6853 - val_acc: 0.5729\n",
      "Epoch 1152/1500\n",
      "Epoch 01151: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6853 - val_acc: 0.5729\n",
      "Epoch 1153/1500\n",
      "Epoch 01152: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6853 - val_acc: 0.5729\n",
      "Epoch 1154/1500\n",
      "Epoch 01153: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6853 - val_acc: 0.5729\n",
      "Epoch 1155/1500\n",
      "Epoch 01154: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6853 - val_acc: 0.5729\n",
      "Epoch 1156/1500\n",
      "Epoch 01155: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6853 - val_acc: 0.5729\n",
      "Epoch 1157/1500\n",
      "Epoch 01156: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6854 - val_acc: 0.5729\n",
      "Epoch 1158/1500\n",
      "Epoch 01157: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6854 - val_acc: 0.5729\n",
      "Epoch 1159/1500\n",
      "Epoch 01158: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6854 - val_acc: 0.5729\n",
      "Epoch 1160/1500\n",
      "Epoch 01159: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6854 - val_acc: 0.5729\n",
      "Epoch 1161/1500\n",
      "Epoch 01160: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6854 - val_acc: 0.5729\n",
      "Epoch 1162/1500\n",
      "Epoch 01161: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6854 - val_acc: 0.5729\n",
      "Epoch 1163/1500\n",
      "Epoch 01162: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6854 - val_acc: 0.5729\n",
      "Epoch 1164/1500\n",
      "Epoch 01163: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6906 - acc: 0.5319 - val_loss: 0.6854 - val_acc: 0.5729\n",
      "Epoch 1165/1500\n",
      "Epoch 01164: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6854 - val_acc: 0.5729\n",
      "Epoch 1166/1500\n",
      "Epoch 01165: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6854 - val_acc: 0.5729\n",
      "Epoch 1167/1500\n",
      "Epoch 01166: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6854 - val_acc: 0.5729\n",
      "Epoch 1168/1500\n",
      "Epoch 01167: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6854 - val_acc: 0.5729\n",
      "Epoch 1169/1500\n",
      "Epoch 01168: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6854 - val_acc: 0.5729\n",
      "Epoch 1170/1500\n",
      "Epoch 01169: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6854 - val_acc: 0.5729\n",
      "Epoch 1171/1500\n",
      "Epoch 01170: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6854 - val_acc: 0.5729\n",
      "Epoch 1172/1500\n",
      "Epoch 01171: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6854 - val_acc: 0.5729\n",
      "Epoch 1173/1500\n",
      "Epoch 01172: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6854 - val_acc: 0.5729\n",
      "Epoch 1174/1500\n",
      "Epoch 01173: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6854 - val_acc: 0.5729\n",
      "Epoch 1175/1500\n",
      "Epoch 01174: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6855 - val_acc: 0.5729\n",
      "Epoch 1176/1500\n",
      "Epoch 01175: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6855 - val_acc: 0.5729\n",
      "Epoch 1177/1500\n",
      "Epoch 01176: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6855 - val_acc: 0.5729\n",
      "Epoch 1178/1500\n",
      "Epoch 01177: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6855 - val_acc: 0.5729\n",
      "Epoch 1179/1500\n",
      "Epoch 01178: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6855 - val_acc: 0.5729\n",
      "Epoch 1180/1500\n",
      "Epoch 01179: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6855 - val_acc: 0.5729\n",
      "Epoch 1181/1500\n",
      "Epoch 01180: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6855 - val_acc: 0.5729\n",
      "Epoch 1182/1500\n",
      "Epoch 01181: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6855 - val_acc: 0.5729\n",
      "Epoch 1183/1500\n",
      "Epoch 01182: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6855 - val_acc: 0.5729\n",
      "Epoch 1184/1500\n",
      "Epoch 01183: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6855 - val_acc: 0.5729\n",
      "Epoch 1185/1500\n",
      "Epoch 01184: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6855 - val_acc: 0.5729\n",
      "Epoch 1186/1500\n",
      "Epoch 01185: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6855 - val_acc: 0.5729\n",
      "Epoch 1187/1500\n",
      "Epoch 01186: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6855 - val_acc: 0.5729\n",
      "Epoch 1188/1500\n",
      "Epoch 01187: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6855 - val_acc: 0.5729\n",
      "Epoch 1189/1500\n",
      "Epoch 01188: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6855 - val_acc: 0.5729\n",
      "Epoch 1190/1500\n",
      "Epoch 01189: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6855 - val_acc: 0.5729\n",
      "Epoch 1191/1500\n",
      "Epoch 01190: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6855 - val_acc: 0.5729\n",
      "Epoch 1192/1500\n",
      "Epoch 01191: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6855 - val_acc: 0.5729\n",
      "Epoch 1193/1500\n",
      "Epoch 01192: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6855 - val_acc: 0.5729\n",
      "Epoch 1194/1500\n",
      "Epoch 01193: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6855 - val_acc: 0.5729\n",
      "Epoch 1195/1500\n",
      "Epoch 01194: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6856 - val_acc: 0.5729\n",
      "Epoch 1196/1500\n",
      "Epoch 01195: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6856 - val_acc: 0.5729\n",
      "Epoch 1197/1500\n",
      "Epoch 01196: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6856 - val_acc: 0.5729\n",
      "Epoch 1198/1500\n",
      "Epoch 01197: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6856 - val_acc: 0.5729\n",
      "Epoch 1199/1500\n",
      "Epoch 01198: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6856 - val_acc: 0.5729\n",
      "Epoch 1200/1500\n",
      "Epoch 01199: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6856 - val_acc: 0.5729\n",
      "Epoch 1201/1500\n",
      "Epoch 01200: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6856 - val_acc: 0.5729\n",
      "Epoch 1202/1500\n",
      "Epoch 01201: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6856 - val_acc: 0.5729\n",
      "Epoch 1203/1500\n",
      "Epoch 01202: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6856 - val_acc: 0.5729\n",
      "Epoch 1204/1500\n",
      "Epoch 01203: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6856 - val_acc: 0.5729\n",
      "Epoch 1205/1500\n",
      "Epoch 01204: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6856 - val_acc: 0.5729\n",
      "Epoch 1206/1500\n",
      "Epoch 01205: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6856 - val_acc: 0.5729\n",
      "Epoch 1207/1500\n",
      "Epoch 01206: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6856 - val_acc: 0.5729\n",
      "Epoch 1208/1500\n",
      "Epoch 01207: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6856 - val_acc: 0.5729\n",
      "Epoch 1209/1500\n",
      "Epoch 01208: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6856 - val_acc: 0.5729\n",
      "Epoch 1210/1500\n",
      "Epoch 01209: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6856 - val_acc: 0.5729\n",
      "Epoch 1211/1500\n",
      "Epoch 01210: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6856 - val_acc: 0.5729\n",
      "Epoch 1212/1500\n",
      "Epoch 01211: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6857 - val_acc: 0.5729\n",
      "Epoch 1213/1500\n",
      "Epoch 01212: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6857 - val_acc: 0.5729\n",
      "Epoch 1214/1500\n",
      "Epoch 01213: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6857 - val_acc: 0.5729\n",
      "Epoch 1215/1500\n",
      "Epoch 01214: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6857 - val_acc: 0.5729\n",
      "Epoch 1216/1500\n",
      "Epoch 01215: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6857 - val_acc: 0.5729\n",
      "Epoch 1217/1500\n",
      "Epoch 01216: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6857 - val_acc: 0.5729\n",
      "Epoch 1218/1500\n",
      "Epoch 01217: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6857 - val_acc: 0.5729\n",
      "Epoch 1219/1500\n",
      "Epoch 01218: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6857 - val_acc: 0.5729\n",
      "Epoch 1220/1500\n",
      "Epoch 01219: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6857 - val_acc: 0.5729\n",
      "Epoch 1221/1500\n",
      "Epoch 01220: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6857 - val_acc: 0.5729\n",
      "Epoch 1222/1500\n",
      "Epoch 01221: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6857 - val_acc: 0.5729\n",
      "Epoch 1223/1500\n",
      "Epoch 01222: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6857 - val_acc: 0.5729\n",
      "Epoch 1224/1500\n",
      "Epoch 01223: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6857 - val_acc: 0.5729\n",
      "Epoch 1225/1500\n",
      "Epoch 01224: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6857 - val_acc: 0.5729\n",
      "Epoch 1226/1500\n",
      "Epoch 01225: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6857 - val_acc: 0.5729\n",
      "Epoch 1227/1500\n",
      "Epoch 01226: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6857 - val_acc: 0.5729\n",
      "Epoch 1228/1500\n",
      "Epoch 01227: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6858 - val_acc: 0.5729\n",
      "Epoch 1229/1500\n",
      "Epoch 01228: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6858 - val_acc: 0.5729\n",
      "Epoch 1230/1500\n",
      "Epoch 01229: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6858 - val_acc: 0.5729\n",
      "Epoch 1231/1500\n",
      "Epoch 01230: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6858 - val_acc: 0.5729\n",
      "Epoch 1232/1500\n",
      "Epoch 01231: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6858 - val_acc: 0.5729\n",
      "Epoch 1233/1500\n",
      "Epoch 01232: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6858 - val_acc: 0.5729\n",
      "Epoch 1234/1500\n",
      "Epoch 01233: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6858 - val_acc: 0.5729\n",
      "Epoch 1235/1500\n",
      "Epoch 01234: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6858 - val_acc: 0.5729\n",
      "Epoch 1236/1500\n",
      "Epoch 01235: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6858 - val_acc: 0.5729\n",
      "Epoch 1237/1500\n",
      "Epoch 01236: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6858 - val_acc: 0.5729\n",
      "Epoch 1238/1500\n",
      "Epoch 01237: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6858 - val_acc: 0.5729\n",
      "Epoch 1239/1500\n",
      "Epoch 01238: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6858 - val_acc: 0.5729\n",
      "Epoch 1240/1500\n",
      "Epoch 01239: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1241/1500\n",
      "Epoch 01240: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1242/1500\n",
      "Epoch 01241: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1243/1500\n",
      "Epoch 01242: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1244/1500\n",
      "Epoch 01243: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1245/1500\n",
      "Epoch 01244: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1246/1500\n",
      "Epoch 01245: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1247/1500\n",
      "Epoch 01246: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1248/1500\n",
      "Epoch 01247: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1249/1500\n",
      "Epoch 01248: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1250/1500\n",
      "Epoch 01249: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1251/1500\n",
      "Epoch 01250: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1252/1500\n",
      "Epoch 01251: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1253/1500\n",
      "Epoch 01252: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1254/1500\n",
      "Epoch 01253: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1255/1500\n",
      "Epoch 01254: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1256/1500\n",
      "Epoch 01255: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6905 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1257/1500\n",
      "Epoch 01256: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1258/1500\n",
      "Epoch 01257: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1259/1500\n",
      "Epoch 01258: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6860 - val_acc: 0.5729\n",
      "Epoch 1260/1500\n",
      "Epoch 01259: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6860 - val_acc: 0.5729\n",
      "Epoch 1261/1500\n",
      "Epoch 01260: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6860 - val_acc: 0.5729\n",
      "Epoch 1262/1500\n",
      "Epoch 01261: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6860 - val_acc: 0.5729\n",
      "Epoch 1263/1500\n",
      "Epoch 01262: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6860 - val_acc: 0.5729\n",
      "Epoch 1264/1500\n",
      "Epoch 01263: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6860 - val_acc: 0.5729\n",
      "Epoch 1265/1500\n",
      "Epoch 01264: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6860 - val_acc: 0.5729\n",
      "Epoch 1266/1500\n",
      "Epoch 01265: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6860 - val_acc: 0.5729\n",
      "Epoch 1267/1500\n",
      "Epoch 01266: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6860 - val_acc: 0.5729\n",
      "Epoch 1268/1500\n",
      "Epoch 01267: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6860 - val_acc: 0.5729\n",
      "Epoch 1269/1500\n",
      "Epoch 01268: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6860 - val_acc: 0.5729\n",
      "Epoch 1270/1500\n",
      "Epoch 01269: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6860 - val_acc: 0.5729\n",
      "Epoch 1271/1500\n",
      "Epoch 01270: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6860 - val_acc: 0.5729\n",
      "Epoch 1272/1500\n",
      "Epoch 01271: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1273/1500\n",
      "Epoch 01272: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1274/1500\n",
      "Epoch 01273: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1275/1500\n",
      "Epoch 01274: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1276/1500\n",
      "Epoch 01275: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1277/1500\n",
      "Epoch 01276: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1278/1500\n",
      "Epoch 01277: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6858 - val_acc: 0.5729\n",
      "Epoch 1279/1500\n",
      "Epoch 01278: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6858 - val_acc: 0.5729\n",
      "Epoch 1280/1500\n",
      "Epoch 01279: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6858 - val_acc: 0.5729\n",
      "Epoch 1281/1500\n",
      "Epoch 01280: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6858 - val_acc: 0.5729\n",
      "Epoch 1282/1500\n",
      "Epoch 01281: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6858 - val_acc: 0.5729\n",
      "Epoch 1283/1500\n",
      "Epoch 01282: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6858 - val_acc: 0.5729\n",
      "Epoch 1284/1500\n",
      "Epoch 01283: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6858 - val_acc: 0.5729\n",
      "Epoch 1285/1500\n",
      "Epoch 01284: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6858 - val_acc: 0.5729\n",
      "Epoch 1286/1500\n",
      "Epoch 01285: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6858 - val_acc: 0.5729\n",
      "Epoch 1287/1500\n",
      "Epoch 01286: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1288/1500\n",
      "Epoch 01287: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1289/1500\n",
      "Epoch 01288: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1290/1500\n",
      "Epoch 01289: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1291/1500\n",
      "Epoch 01290: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1292/1500\n",
      "Epoch 01291: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1293/1500\n",
      "Epoch 01292: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1294/1500\n",
      "Epoch 01293: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1295/1500\n",
      "Epoch 01294: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1296/1500\n",
      "Epoch 01295: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1297/1500\n",
      "Epoch 01296: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1298/1500\n",
      "Epoch 01297: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6859 - val_acc: 0.5729\n",
      "Epoch 1299/1500\n",
      "Epoch 01298: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6860 - val_acc: 0.5729\n",
      "Epoch 1300/1500\n",
      "Epoch 01299: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6860 - val_acc: 0.5729\n",
      "Epoch 1301/1500\n",
      "Epoch 01300: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6860 - val_acc: 0.5729\n",
      "Epoch 1302/1500\n",
      "Epoch 01301: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6860 - val_acc: 0.5729\n",
      "Epoch 1303/1500\n",
      "Epoch 01302: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6861 - val_acc: 0.5729\n",
      "Epoch 1304/1500\n",
      "Epoch 01303: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6861 - val_acc: 0.5729\n",
      "Epoch 1305/1500\n",
      "Epoch 01304: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6861 - val_acc: 0.5729\n",
      "Epoch 1306/1500\n",
      "Epoch 01305: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6861 - val_acc: 0.5729\n",
      "Epoch 1307/1500\n",
      "Epoch 01306: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6861 - val_acc: 0.5729\n",
      "Epoch 1308/1500\n",
      "Epoch 01307: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6862 - val_acc: 0.5729\n",
      "Epoch 1309/1500\n",
      "Epoch 01308: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6862 - val_acc: 0.5729\n",
      "Epoch 1310/1500\n",
      "Epoch 01309: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6862 - val_acc: 0.5729\n",
      "Epoch 1311/1500\n",
      "Epoch 01310: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6862 - val_acc: 0.5729\n",
      "Epoch 1312/1500\n",
      "Epoch 01311: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6904 - acc: 0.5319 - val_loss: 0.6862 - val_acc: 0.5729\n",
      "Epoch 1313/1500\n",
      "Epoch 01312: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6862 - val_acc: 0.5729\n",
      "Epoch 1314/1500\n",
      "Epoch 01313: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6862 - val_acc: 0.5729\n",
      "Epoch 1315/1500\n",
      "Epoch 01314: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6862 - val_acc: 0.5729\n",
      "Epoch 1316/1500\n",
      "Epoch 01315: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6862 - val_acc: 0.5729\n",
      "Epoch 1317/1500\n",
      "Epoch 01316: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6862 - val_acc: 0.5729\n",
      "Epoch 1318/1500\n",
      "Epoch 01317: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6863 - val_acc: 0.5729\n",
      "Epoch 1319/1500\n",
      "Epoch 01318: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6863 - val_acc: 0.5729\n",
      "Epoch 1320/1500\n",
      "Epoch 01319: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6863 - val_acc: 0.5729\n",
      "Epoch 1321/1500\n",
      "Epoch 01320: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6863 - val_acc: 0.5729\n",
      "Epoch 1322/1500\n",
      "Epoch 01321: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6863 - val_acc: 0.5729\n",
      "Epoch 1323/1500\n",
      "Epoch 01322: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6863 - val_acc: 0.5729\n",
      "Epoch 1324/1500\n",
      "Epoch 01323: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6863 - val_acc: 0.5729\n",
      "Epoch 1325/1500\n",
      "Epoch 01324: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6863 - val_acc: 0.5729\n",
      "Epoch 1326/1500\n",
      "Epoch 01325: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6863 - val_acc: 0.5729\n",
      "Epoch 1327/1500\n",
      "Epoch 01326: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6863 - val_acc: 0.5729\n",
      "Epoch 1328/1500\n",
      "Epoch 01327: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6863 - val_acc: 0.5729\n",
      "Epoch 1329/1500\n",
      "Epoch 01328: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6863 - val_acc: 0.5729\n",
      "Epoch 1330/1500\n",
      "Epoch 01329: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6863 - val_acc: 0.5729\n",
      "Epoch 1331/1500\n",
      "Epoch 01330: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6864 - val_acc: 0.5729\n",
      "Epoch 1332/1500\n",
      "Epoch 01331: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6864 - val_acc: 0.5729\n",
      "Epoch 1333/1500\n",
      "Epoch 01332: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6864 - val_acc: 0.5729\n",
      "Epoch 1334/1500\n",
      "Epoch 01333: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6864 - val_acc: 0.5729\n",
      "Epoch 1335/1500\n",
      "Epoch 01334: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6864 - val_acc: 0.5729\n",
      "Epoch 1336/1500\n",
      "Epoch 01335: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6864 - val_acc: 0.5729\n",
      "Epoch 1337/1500\n",
      "Epoch 01336: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6864 - val_acc: 0.5729\n",
      "Epoch 1338/1500\n",
      "Epoch 01337: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6864 - val_acc: 0.5729\n",
      "Epoch 1339/1500\n",
      "Epoch 01338: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6865 - val_acc: 0.5729\n",
      "Epoch 1340/1500\n",
      "Epoch 01339: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6865 - val_acc: 0.5729\n",
      "Epoch 1341/1500\n",
      "Epoch 01340: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6865 - val_acc: 0.5729\n",
      "Epoch 1342/1500\n",
      "Epoch 01341: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6865 - val_acc: 0.5729\n",
      "Epoch 1343/1500\n",
      "Epoch 01342: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6865 - val_acc: 0.5729\n",
      "Epoch 1344/1500\n",
      "Epoch 01343: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6865 - val_acc: 0.5729\n",
      "Epoch 1345/1500\n",
      "Epoch 01344: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6865 - val_acc: 0.5729\n",
      "Epoch 1346/1500\n",
      "Epoch 01345: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6865 - val_acc: 0.5729\n",
      "Epoch 1347/1500\n",
      "Epoch 01346: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6865 - val_acc: 0.5729\n",
      "Epoch 1348/1500\n",
      "Epoch 01347: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6865 - val_acc: 0.5729\n",
      "Epoch 1349/1500\n",
      "Epoch 01348: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6866 - val_acc: 0.5729\n",
      "Epoch 1350/1500\n",
      "Epoch 01349: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6866 - val_acc: 0.5729\n",
      "Epoch 1351/1500\n",
      "Epoch 01350: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6866 - val_acc: 0.5729\n",
      "Epoch 1352/1500\n",
      "Epoch 01351: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6866 - val_acc: 0.5729\n",
      "Epoch 1353/1500\n",
      "Epoch 01352: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6866 - val_acc: 0.5729\n",
      "Epoch 1354/1500\n",
      "Epoch 01353: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6866 - val_acc: 0.5729\n",
      "Epoch 1355/1500\n",
      "Epoch 01354: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6866 - val_acc: 0.5729\n",
      "Epoch 1356/1500\n",
      "Epoch 01355: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6866 - val_acc: 0.5729\n",
      "Epoch 1357/1500\n",
      "Epoch 01356: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6866 - val_acc: 0.5729\n",
      "Epoch 1358/1500\n",
      "Epoch 01357: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6866 - val_acc: 0.5729\n",
      "Epoch 1359/1500\n",
      "Epoch 01358: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6866 - val_acc: 0.5729\n",
      "Epoch 1360/1500\n",
      "Epoch 01359: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6866 - val_acc: 0.5729\n",
      "Epoch 1361/1500\n",
      "Epoch 01360: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6867 - val_acc: 0.5729\n",
      "Epoch 1362/1500\n",
      "Epoch 01361: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6867 - val_acc: 0.5729\n",
      "Epoch 1363/1500\n",
      "Epoch 01362: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6867 - val_acc: 0.5729\n",
      "Epoch 1364/1500\n",
      "Epoch 01363: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6867 - val_acc: 0.5729\n",
      "Epoch 1365/1500\n",
      "Epoch 01364: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6867 - val_acc: 0.5729\n",
      "Epoch 1366/1500\n",
      "Epoch 01365: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6867 - val_acc: 0.5729\n",
      "Epoch 1367/1500\n",
      "Epoch 01366: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6867 - val_acc: 0.5729\n",
      "Epoch 1368/1500\n",
      "Epoch 01367: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6867 - val_acc: 0.5729\n",
      "Epoch 1369/1500\n",
      "Epoch 01368: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5319 - val_loss: 0.6867 - val_acc: 0.5729\n",
      "Epoch 1370/1500\n",
      "Epoch 01369: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5307 - val_loss: 0.6867 - val_acc: 0.5729\n",
      "Epoch 1371/1500\n",
      "Epoch 01370: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5307 - val_loss: 0.6867 - val_acc: 0.5729\n",
      "Epoch 1372/1500\n",
      "Epoch 01371: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5307 - val_loss: 0.6867 - val_acc: 0.5729\n",
      "Epoch 1373/1500\n",
      "Epoch 01372: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5307 - val_loss: 0.6868 - val_acc: 0.5729\n",
      "Epoch 1374/1500\n",
      "Epoch 01373: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5307 - val_loss: 0.6868 - val_acc: 0.5729\n",
      "Epoch 1375/1500\n",
      "Epoch 01374: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5307 - val_loss: 0.6868 - val_acc: 0.5729\n",
      "Epoch 1376/1500\n",
      "Epoch 01375: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5307 - val_loss: 0.6868 - val_acc: 0.5729\n",
      "Epoch 1377/1500\n",
      "Epoch 01376: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5307 - val_loss: 0.6868 - val_acc: 0.5729\n",
      "Epoch 1378/1500\n",
      "Epoch 01377: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5307 - val_loss: 0.6868 - val_acc: 0.5729\n",
      "Epoch 1379/1500\n",
      "Epoch 01378: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5307 - val_loss: 0.6868 - val_acc: 0.5729\n",
      "Epoch 1380/1500\n",
      "Epoch 01379: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5307 - val_loss: 0.6868 - val_acc: 0.5729\n",
      "Epoch 1381/1500\n",
      "Epoch 01380: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5307 - val_loss: 0.6868 - val_acc: 0.5729\n",
      "Epoch 1382/1500\n",
      "Epoch 01381: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5307 - val_loss: 0.6868 - val_acc: 0.5729\n",
      "Epoch 1383/1500\n",
      "Epoch 01382: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5307 - val_loss: 0.6868 - val_acc: 0.5729\n",
      "Epoch 1384/1500\n",
      "Epoch 01383: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6903 - acc: 0.5307 - val_loss: 0.6869 - val_acc: 0.5729\n",
      "Epoch 1385/1500\n",
      "Epoch 01384: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5307 - val_loss: 0.6869 - val_acc: 0.5729\n",
      "Epoch 1386/1500\n",
      "Epoch 01385: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5307 - val_loss: 0.6869 - val_acc: 0.5729\n",
      "Epoch 1387/1500\n",
      "Epoch 01386: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5307 - val_loss: 0.6869 - val_acc: 0.5729\n",
      "Epoch 1388/1500\n",
      "Epoch 01387: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5307 - val_loss: 0.6869 - val_acc: 0.5729\n",
      "Epoch 1389/1500\n",
      "Epoch 01388: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5307 - val_loss: 0.6869 - val_acc: 0.5729\n",
      "Epoch 1390/1500\n",
      "Epoch 01389: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5307 - val_loss: 0.6869 - val_acc: 0.5729\n",
      "Epoch 1391/1500\n",
      "Epoch 01390: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5307 - val_loss: 0.6869 - val_acc: 0.5729\n",
      "Epoch 1392/1500\n",
      "Epoch 01391: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5307 - val_loss: 0.6869 - val_acc: 0.5729\n",
      "Epoch 1393/1500\n",
      "Epoch 01392: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5307 - val_loss: 0.6868 - val_acc: 0.5729\n",
      "Epoch 1394/1500\n",
      "Epoch 01393: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5307 - val_loss: 0.6868 - val_acc: 0.5729\n",
      "Epoch 1395/1500\n",
      "Epoch 01394: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5307 - val_loss: 0.6868 - val_acc: 0.5729\n",
      "Epoch 1396/1500\n",
      "Epoch 01395: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5307 - val_loss: 0.6868 - val_acc: 0.5729\n",
      "Epoch 1397/1500\n",
      "Epoch 01396: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6868 - val_acc: 0.5729\n",
      "Epoch 1398/1500\n",
      "Epoch 01397: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6868 - val_acc: 0.5729\n",
      "Epoch 1399/1500\n",
      "Epoch 01398: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6868 - val_acc: 0.5729\n",
      "Epoch 1400/1500\n",
      "Epoch 01399: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5307 - val_loss: 0.6868 - val_acc: 0.5729\n",
      "Epoch 1401/1500\n",
      "Epoch 01400: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5307 - val_loss: 0.6869 - val_acc: 0.5729\n",
      "Epoch 1402/1500\n",
      "Epoch 01401: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6869 - val_acc: 0.5729\n",
      "Epoch 1403/1500\n",
      "Epoch 01402: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5307 - val_loss: 0.6869 - val_acc: 0.5729\n",
      "Epoch 1404/1500\n",
      "Epoch 01403: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6869 - val_acc: 0.5729\n",
      "Epoch 1405/1500\n",
      "Epoch 01404: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5307 - val_loss: 0.6869 - val_acc: 0.5729\n",
      "Epoch 1406/1500\n",
      "Epoch 01405: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6869 - val_acc: 0.5729\n",
      "Epoch 1407/1500\n",
      "Epoch 01406: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6869 - val_acc: 0.5729\n",
      "Epoch 1408/1500\n",
      "Epoch 01407: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5284 - val_loss: 0.6869 - val_acc: 0.5729\n",
      "Epoch 1409/1500\n",
      "Epoch 01408: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6869 - val_acc: 0.5729\n",
      "Epoch 1410/1500\n",
      "Epoch 01409: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6869 - val_acc: 0.5729\n",
      "Epoch 1411/1500\n",
      "Epoch 01410: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5284 - val_loss: 0.6869 - val_acc: 0.5729\n",
      "Epoch 1412/1500\n",
      "Epoch 01411: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5272 - val_loss: 0.6869 - val_acc: 0.5729\n",
      "Epoch 1413/1500\n",
      "Epoch 01412: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6869 - val_acc: 0.5729\n",
      "Epoch 1414/1500\n",
      "Epoch 01413: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5307 - val_loss: 0.6869 - val_acc: 0.5729\n",
      "Epoch 1415/1500\n",
      "Epoch 01414: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5307 - val_loss: 0.6869 - val_acc: 0.5729\n",
      "Epoch 1416/1500\n",
      "Epoch 01415: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6870 - val_acc: 0.5729\n",
      "Epoch 1417/1500\n",
      "Epoch 01416: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6870 - val_acc: 0.5729\n",
      "Epoch 1418/1500\n",
      "Epoch 01417: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6870 - val_acc: 0.5729\n",
      "Epoch 1419/1500\n",
      "Epoch 01418: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6870 - val_acc: 0.5729\n",
      "Epoch 1420/1500\n",
      "Epoch 01419: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5284 - val_loss: 0.6870 - val_acc: 0.5729\n",
      "Epoch 1421/1500\n",
      "Epoch 01420: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5284 - val_loss: 0.6870 - val_acc: 0.5729\n",
      "Epoch 1422/1500\n",
      "Epoch 01421: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6870 - val_acc: 0.5729\n",
      "Epoch 1423/1500\n",
      "Epoch 01422: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6870 - val_acc: 0.5729\n",
      "Epoch 1424/1500\n",
      "Epoch 01423: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6871 - val_acc: 0.5729\n",
      "Epoch 1425/1500\n",
      "Epoch 01424: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6871 - val_acc: 0.5729\n",
      "Epoch 1426/1500\n",
      "Epoch 01425: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6871 - val_acc: 0.5729\n",
      "Epoch 1427/1500\n",
      "Epoch 01426: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6871 - val_acc: 0.5729\n",
      "Epoch 1428/1500\n",
      "Epoch 01427: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6871 - val_acc: 0.5729\n",
      "Epoch 1429/1500\n",
      "Epoch 01428: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6871 - val_acc: 0.5729\n",
      "Epoch 1430/1500\n",
      "Epoch 01429: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6871 - val_acc: 0.5729\n",
      "Epoch 1431/1500\n",
      "Epoch 01430: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6872 - val_acc: 0.5729\n",
      "Epoch 1432/1500\n",
      "Epoch 01431: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6872 - val_acc: 0.5729\n",
      "Epoch 1433/1500\n",
      "Epoch 01432: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6872 - val_acc: 0.5729\n",
      "Epoch 1434/1500\n",
      "Epoch 01433: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6872 - val_acc: 0.5729\n",
      "Epoch 1435/1500\n",
      "Epoch 01434: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6872 - val_acc: 0.5729\n",
      "Epoch 1436/1500\n",
      "Epoch 01435: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6872 - val_acc: 0.5729\n",
      "Epoch 1437/1500\n",
      "Epoch 01436: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6872 - val_acc: 0.5729\n",
      "Epoch 1438/1500\n",
      "Epoch 01437: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6872 - val_acc: 0.5729\n",
      "Epoch 1439/1500\n",
      "Epoch 01438: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6872 - val_acc: 0.5729\n",
      "Epoch 1440/1500\n",
      "Epoch 01439: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6873 - val_acc: 0.5729\n",
      "Epoch 1441/1500\n",
      "Epoch 01440: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6873 - val_acc: 0.5729\n",
      "Epoch 1442/1500\n",
      "Epoch 01441: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6902 - acc: 0.5295 - val_loss: 0.6873 - val_acc: 0.5729\n",
      "Epoch 1443/1500\n",
      "Epoch 01442: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6873 - val_acc: 0.5729\n",
      "Epoch 1444/1500\n",
      "Epoch 01443: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6873 - val_acc: 0.5729\n",
      "Epoch 1445/1500\n",
      "Epoch 01444: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6873 - val_acc: 0.5729\n",
      "Epoch 1446/1500\n",
      "Epoch 01445: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6873 - val_acc: 0.5729\n",
      "Epoch 1447/1500\n",
      "Epoch 01446: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6873 - val_acc: 0.5729\n",
      "Epoch 1448/1500\n",
      "Epoch 01447: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6873 - val_acc: 0.5729\n",
      "Epoch 1449/1500\n",
      "Epoch 01448: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6873 - val_acc: 0.5729\n",
      "Epoch 1450/1500\n",
      "Epoch 01449: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6874 - val_acc: 0.5729\n",
      "Epoch 1451/1500\n",
      "Epoch 01450: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6874 - val_acc: 0.5729\n",
      "Epoch 1452/1500\n",
      "Epoch 01451: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6874 - val_acc: 0.5729\n",
      "Epoch 1453/1500\n",
      "Epoch 01452: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6874 - val_acc: 0.5729\n",
      "Epoch 1454/1500\n",
      "Epoch 01453: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6874 - val_acc: 0.5729\n",
      "Epoch 1455/1500\n",
      "Epoch 01454: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6874 - val_acc: 0.5729\n",
      "Epoch 1456/1500\n",
      "Epoch 01455: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6874 - val_acc: 0.5729\n",
      "Epoch 1457/1500\n",
      "Epoch 01456: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6874 - val_acc: 0.5729\n",
      "Epoch 1458/1500\n",
      "Epoch 01457: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6874 - val_acc: 0.5729\n",
      "Epoch 1459/1500\n",
      "Epoch 01458: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6874 - val_acc: 0.5729\n",
      "Epoch 1460/1500\n",
      "Epoch 01459: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6875 - val_acc: 0.5729\n",
      "Epoch 1461/1500\n",
      "Epoch 01460: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6875 - val_acc: 0.5729\n",
      "Epoch 1462/1500\n",
      "Epoch 01461: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6875 - val_acc: 0.5729\n",
      "Epoch 1463/1500\n",
      "Epoch 01462: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6875 - val_acc: 0.5729\n",
      "Epoch 1464/1500\n",
      "Epoch 01463: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6875 - val_acc: 0.5729\n",
      "Epoch 1465/1500\n",
      "Epoch 01464: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6875 - val_acc: 0.5729\n",
      "Epoch 1466/1500\n",
      "Epoch 01465: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6875 - val_acc: 0.5729\n",
      "Epoch 1467/1500\n",
      "Epoch 01466: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6875 - val_acc: 0.5729\n",
      "Epoch 1468/1500\n",
      "Epoch 01467: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6875 - val_acc: 0.5729\n",
      "Epoch 1469/1500\n",
      "Epoch 01468: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6876 - val_acc: 0.5729\n",
      "Epoch 1470/1500\n",
      "Epoch 01469: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6876 - val_acc: 0.5729\n",
      "Epoch 1471/1500\n",
      "Epoch 01470: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6876 - val_acc: 0.5729\n",
      "Epoch 1472/1500\n",
      "Epoch 01471: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6876 - val_acc: 0.5729\n",
      "Epoch 1473/1500\n",
      "Epoch 01472: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6876 - val_acc: 0.5729\n",
      "Epoch 1474/1500\n",
      "Epoch 01473: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6876 - val_acc: 0.5729\n",
      "Epoch 1475/1500\n",
      "Epoch 01474: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6876 - val_acc: 0.5729\n",
      "Epoch 1476/1500\n",
      "Epoch 01475: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6876 - val_acc: 0.5729\n",
      "Epoch 1477/1500\n",
      "Epoch 01476: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6876 - val_acc: 0.5729\n",
      "Epoch 1478/1500\n",
      "Epoch 01477: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6876 - val_acc: 0.5729\n",
      "Epoch 1479/1500\n",
      "Epoch 01478: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6877 - val_acc: 0.5729\n",
      "Epoch 1480/1500\n",
      "Epoch 01479: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6877 - val_acc: 0.5729\n",
      "Epoch 1481/1500\n",
      "Epoch 01480: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6877 - val_acc: 0.5729\n",
      "Epoch 1482/1500\n",
      "Epoch 01481: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6877 - val_acc: 0.5729\n",
      "Epoch 1483/1500\n",
      "Epoch 01482: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6877 - val_acc: 0.5729\n",
      "Epoch 1484/1500\n",
      "Epoch 01483: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6877 - val_acc: 0.5729\n",
      "Epoch 1485/1500\n",
      "Epoch 01484: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6877 - val_acc: 0.5729\n",
      "Epoch 1486/1500\n",
      "Epoch 01485: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6877 - val_acc: 0.5729\n",
      "Epoch 1487/1500\n",
      "Epoch 01486: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6877 - val_acc: 0.5729\n",
      "Epoch 1488/1500\n",
      "Epoch 01487: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6878 - val_acc: 0.5729\n",
      "Epoch 1489/1500\n",
      "Epoch 01488: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6878 - val_acc: 0.5729\n",
      "Epoch 1490/1500\n",
      "Epoch 01489: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6878 - val_acc: 0.5729\n",
      "Epoch 1491/1500\n",
      "Epoch 01490: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6901 - acc: 0.5295 - val_loss: 0.6878 - val_acc: 0.5729\n",
      "Epoch 1492/1500\n",
      "Epoch 01491: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6900 - acc: 0.5295 - val_loss: 0.6878 - val_acc: 0.5729\n",
      "Epoch 1493/1500\n",
      "Epoch 01492: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6900 - acc: 0.5284 - val_loss: 0.6878 - val_acc: 0.5729\n",
      "Epoch 1494/1500\n",
      "Epoch 01493: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6900 - acc: 0.5284 - val_loss: 0.6878 - val_acc: 0.5729\n",
      "Epoch 1495/1500\n",
      "Epoch 01494: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6900 - acc: 0.5284 - val_loss: 0.6878 - val_acc: 0.5729\n",
      "Epoch 1496/1500\n",
      "Epoch 01495: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6900 - acc: 0.5284 - val_loss: 0.6878 - val_acc: 0.5729\n",
      "Epoch 1497/1500\n",
      "Epoch 01496: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6900 - acc: 0.5284 - val_loss: 0.6879 - val_acc: 0.5729\n",
      "Epoch 1498/1500\n",
      "Epoch 01497: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6900 - acc: 0.5284 - val_loss: 0.6879 - val_acc: 0.5729\n",
      "Epoch 1499/1500\n",
      "Epoch 01498: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6900 - acc: 0.5284 - val_loss: 0.6879 - val_acc: 0.5729\n",
      "Epoch 1500/1500\n",
      "Epoch 01499: val_loss did not improve\n",
      "863/863 [==============================] - 0s - loss: 0.6900 - acc: 0.5284 - val_loss: 0.6879 - val_acc: 0.5729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcaba6b9eb8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "epochs = 1500\n",
    "batch_size = 1000\n",
    "\n",
    "# model.load_weights('saved_models/weights.test_run')\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.test_run.hdf5', \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(trainX, trainY, nb_epoch=epochs, batch_size=batch_size, validation_split=0.1, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 32/228 [===>..........................] - ETA: 1s"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "model.load_weights('saved_models/weights.test_run.hdf5')\n",
    "# trainPredict = model.predict_classes(trainX)\n",
    "testPredict = model.predict_classes(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 0 0 0 1 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0\n",
      " 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1\n",
      " 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 1 1\n",
      " 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1\n",
      " 0 1 1 1 1 1]\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "print(testY)\n",
    "print(testPredict)\n",
    "# num = 670\n",
    "# print(target[num])\n",
    "# print(data_AAPL_close[num-1])\n",
    "# print(data_AAPL_close[num])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
